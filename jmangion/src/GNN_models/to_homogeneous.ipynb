{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "zNycVrw95vU9"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv, HeteroConv"
      ],
      "metadata": {
        "id": "zq5tLgUA58t3"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import HeteroData"
      ],
      "metadata": {
        "id": "TG0CVR9w6EuB"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import AMiner\n",
        "dataset = AMiner(root=\"/content/\")\n"
      ],
      "metadata": {
        "id": "SRiSlPgx6Ko8"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]\n",
        "print(data)\n",
        "print(\"-----\")\n",
        "homogeneous_data = data.to_homogeneous()\n",
        "hd = homogeneous_data # for short\n",
        "print(homogeneous_data)\n",
        "# this issue with the data rn is that there are 3441217 nodes in total, and y vector is storing a value for each of those, even though only 246812 of them have labels.\n",
        "# this means that only 246812/3441217 (7%) of the entries in the y vector are real labels\n",
        "# we need to filter out the unlabeled author nodes, the unlabeled venue nodes, and all of the paper nodes (since no paper nodes have labels) in order to form a suitable y vector\n",
        "# for the loss comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnqsGXwi6kjC",
        "outputId": "4bee49d2-4a5c-4f8d-cbe7-cc437ceb1aca"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
            "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
            "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
            "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
            ")\n",
            "-----\n",
            "Data(edge_index=[2, 25036020], y=[3441217], y_index=[3441217], node_type=[4891819], edge_type=[25036020])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting suitable y vector for loss calculation: remove the placeholder labels (-1) for unlabeled nodes\n",
        "print(f\"homogeneous y started out with size: {hd.y.shape}\")\n",
        "processed_y = hd.y[hd.y != -1]\n",
        "print(f\"After removing the placeholder labels, homogeneous y now has size: {processed_y.shape}\")\n",
        "data.y = processed_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpGKKQQa6-Px",
        "outputId": "1d550283-fa73-42fc-d691-9e54d8e5fb44"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "homogeneous y started out with size: torch.Size([3441217])\n",
            "After removing the placeholder labels, homogeneous y now has size: torch.Size([246812])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming we already have the logits from the model\n",
        "logits = torch.rand(hd.y.shape[0], hd.y.max() + 1) # using hd.y.max() + 1 to include all labels up to hd.y.max() and the 0 label\n",
        "print(f\"shape of logits before removing logits without labels: {logits.shape}\")\n",
        "\n",
        "# reorder the logits to match hd.y and remove the logits that match to placeholder labels\n",
        "logits = logits[hd.y_index][hd.y != -1]\n",
        "\n",
        "print(f\"shape of logits after masking out the ones without labels: {logits.shape}\")\n",
        "print(f\"now the logits with shape: {logits.shape} are aligned with the y labels with shape: {processed_y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjlCYXl4J_95",
        "outputId": "06e62f76-ebd9-4f0e-b731-d74bfbb361e1"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of logits before removing logits without labels: torch.Size([3441217, 8])\n",
            "shape of logits after masking out the ones without labels: torch.Size([246812, 8])\n",
            "now the logits with shape: torch.Size([246812, 8]) are aligned with the y labels with shape: torch.Size([246812])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate nodes by type\n",
        "author_nodes = torch.nonzero(hd.node_type == 0).squeeze()\n",
        "venue_nodes = torch.nonzero(hd.node_type == 1).squeeze()\n",
        "paper_nodes = torch.nonzero(hd.node_type == 2).squeeze()\n",
        "\n",
        "print(f\"shape of author nodes: {author_nodes.shape}\")\n",
        "print(f\"shape of venue nodes: {venue_nodes.shape}\")\n",
        "print(f\"shape of paper nodes: {paper_nodes.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzRu3whSVPzT",
        "outputId": "affc629c-a6db-49ab-80a6-2a8b0a3c6b12"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of author nodes: torch.Size([1693531])\n",
            "shape of venue nodes: torch.Size([3883])\n",
            "shape of paper nodes: torch.Size([3194405])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature vectors as one-hot encodings for each of the nodes\n",
        "# For now they are stored in sparse format to conserve memory\n",
        "import scipy\n",
        "import numpy as np\n",
        "author_nodes_features = scipy.sparse.eye(author_nodes.shape[0], format='coo')\n",
        "venue_nodes_features = scipy.sparse.eye(venue_nodes.shape[0], format='coo')\n",
        "paper_nodes_features = scipy.sparse.eye(paper_nodes.shape[0], format='coo')\n",
        "\n",
        "# move these to torch\n",
        "def scipy_coo_to_torch_sparse(scipy_coo):\n",
        "    values = torch.FloatTensor(scipy_coo.data)\n",
        "    indices = torch.LongTensor(np.vstack((scipy_coo.row, scipy_coo.col)))\n",
        "    shape = torch.Size(scipy_coo.shape)\n",
        "    return torch.sparse_coo_tensor(indices, values, shape)\n",
        "\n",
        "# Convert SciPy sparse matrices to PyTorch sparse tensors\n",
        "author_nodes_features_torch = scipy_coo_to_torch_sparse(author_nodes_features)\n",
        "venue_nodes_features_torch = scipy_coo_to_torch_sparse(venue_nodes_features)\n",
        "paper_nodes_features_torch = scipy_coo_to_torch_sparse(paper_nodes_features)\n",
        "\n",
        "# checking\n",
        "print(f\"shape of author nodes features: {author_nodes_features_torch.shape}\")\n",
        "print(f\"shape of venue nodes features: {venue_nodes_features_torch.shape}\")\n",
        "print(f\"shape of paper nodes features: {paper_nodes_features_torch.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "# pooling all nodes together\n",
        "all_nodes_features = scipy.sparse.eye(hd.node_type.shape[0], format='coo')\n",
        "all_nodes_features_torch = scipy_coo_to_torch_sparse(all_nodes_features)\n",
        "print(all_nodes_features_torch.shape)\n",
        "data.x = all_nodes_features_torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmLzAHsFp78n",
        "outputId": "10470f36-9868-4ffa-d38a-f8901d73bc39"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of author nodes features: torch.Size([1693531, 1693531])\n",
            "shape of venue nodes features: torch.Size([3883, 3883])\n",
            "shape of paper nodes features: torch.Size([3194405, 3194405])\n",
            "torch.Size([4891819, 4891819])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_training_test_validation_masks(y, train_ratio=0.1, validation_ratio=0.1, test_ratio=0.8):\n",
        "  num_train = int(y.shape[0] * train_ratio)\n",
        "  num_val = int(y.shape[0] * validation_ratio)\n",
        "  num_test = int(y.shape[0] * test_ratio)\n",
        "  num_test += 1 # the sum of the train/test/validation splits would otherwise be less than the number of y values\n",
        "\n",
        "  train_counts = [0]*(torch.max(y).item() + 1) # each index of the list represents the number of that index's class label\n",
        "  val_counts = [0]*(torch.max(y).item() +1 )\n",
        "  test_counts = [0]*(torch.max(y).item() + 1)\n",
        "\n",
        "  train_mask = []\n",
        "  val_mask = []\n",
        "  test_mask = []\n",
        "  for y_value in y:\n",
        "    y_value = y_value.item()\n",
        "    ratios = {\"train\" : train_counts[y_value]/num_train, \"val\" : val_counts[y_value]/num_val, \"test\" : test_counts[y_value]/num_test}\n",
        "    priority = min(ratios, key=ratios.get)\n",
        "\n",
        "    train_mask.append(False)\n",
        "    val_mask.append(False)\n",
        "    test_mask.append(False)\n",
        "\n",
        "\n",
        "    if priority == \"train\":\n",
        "      train_mask[-1] = True\n",
        "      train_counts[y_value] += 1\n",
        "\n",
        "    elif priority == \"val\":\n",
        "      val_mask[-1] = True\n",
        "      val_counts[y_value] += 1\n",
        "\n",
        "    elif priority == \"test\":\n",
        "      test_mask[-1] = True\n",
        "      test_counts[y_value] +=1\n",
        "\n",
        "  # this demonstarates that the classes labels are split evenly over the masks\n",
        "  index = 0\n",
        "  for train, val, test in zip(train_counts, val_counts, test_counts):\n",
        "    print(f\"number of label [{index}] in train: {train}\")\n",
        "    print(f\"number of label [{index}] in val: {val}\")\n",
        "    print(f\"number of label [{index}] in test: {test}\")\n",
        "    print(\"------\")\n",
        "    index += 1\n",
        "\n",
        "  return train_mask, val_mask, test_mask\n",
        "\n",
        "\n",
        "train_mask, val_mask, test_mask = make_training_test_validation_masks(processed_y)\n",
        "\n",
        "train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
        "val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
        "test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
        "\n",
        "print(f\"number of train mask labels: {train_mask.nonzero().shape[0]}\")\n",
        "print(f\"number of validation mask labels: {val_mask.nonzero().shape[0]}\")\n",
        "print(f\"number of test mask labels: {test_mask.nonzero().shape[0]}\")\n",
        "# this results in 246812 total true mask values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONze7eG4CcHG",
        "outputId": "27733673-dc54-4797-e186-fd8f23467109"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of label [0] in train: 2893\n",
            "number of label [0] in val: 2893\n",
            "number of label [0] in test: 23143\n",
            "------\n",
            "number of label [1] in train: 6879\n",
            "number of label [1] in val: 6879\n",
            "number of label [1] in test: 55033\n",
            "------\n",
            "number of label [2] in train: 1800\n",
            "number of label [2] in val: 1800\n",
            "number of label [2] in test: 14393\n",
            "------\n",
            "number of label [3] in train: 1593\n",
            "number of label [3] in val: 1593\n",
            "number of label [3] in test: 12742\n",
            "------\n",
            "number of label [4] in train: 2615\n",
            "number of label [4] in val: 2615\n",
            "number of label [4] in test: 20914\n",
            "------\n",
            "number of label [5] in train: 1757\n",
            "number of label [5] in val: 1757\n",
            "number of label [5] in test: 14057\n",
            "------\n",
            "number of label [6] in train: 4573\n",
            "number of label [6] in val: 4573\n",
            "number of label [6] in test: 36583\n",
            "------\n",
            "number of label [7] in train: 2573\n",
            "number of label [7] in val: 2573\n",
            "number of label [7] in test: 20581\n",
            "------\n",
            "number of train mask labels: 24683\n",
            "number of validation mask labels: 24683\n",
            "number of test mask labels: 197446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### arguments.py File ###\n",
        "### Modified for colab since colab does not seem to like argparse ###\n",
        "\n",
        "# Defined custom class to hold arguments\n",
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.root_dir = \"/content\"\n",
        "    self.data_dir = \"/content/data\"\n",
        "    self.epochs = 300\n",
        "    self.runs = 5\n",
        "    self.droput = 0.4\n",
        "    self.lr = 0.001\n",
        "    self.wd = 0.001\n",
        "    self.num_layers = 2\n",
        "    self.num_hidden = 256\n",
        "    self.num_features = 0 # placeholder\n",
        "    self.num_classes = 0 # placeholder\n",
        "\n",
        "def add_data_features(args, data):\n",
        "  args.num_features = data.x.shape[1]\n",
        "  args.num_classes = data.y.shape[0]\n",
        "  return args"
      ],
      "metadata": {
        "id": "vJNQ_bJL215L"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# Display data that was originally used for GCN to get an idea of how to convert new data to its format\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "args = Args()\n",
        "dataset = Planetoid(root=args.root_dir, name=\"Cora\")\n",
        "print(dataset[0])\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Not4F8jI3cd4",
        "outputId": "2f989b6f-62e2-4574-d922-523550f98e50"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# Display data that was originally used for GCN to get an idea of how to convert new data to its format\\nfrom torch_geometric.datasets import Planetoid\\n\\nargs = Args()\\ndataset = Planetoid(root=args.root_dir, name=\"Cora\")\\nprint(dataset[0])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### model.py File ###\n",
        "\n",
        "def make_layers(self):\n",
        "    layers = []\n",
        "    # initialize layers in a loop that uses conditionals to determine the input and output dimensions of the feature vectors\n",
        "    for i in range(self.num_layers):\n",
        "        if i == 0:  # first layer\n",
        "            # dimensions in = input data size\n",
        "            # dimensions out = hidden layer size\n",
        "            layer = GCNConv(self.num_features, self.num_hidden)\n",
        "\n",
        "        elif i < self.num_layers - 1: # hidden layer(s)\n",
        "            # dimensions in = hidden layer size\n",
        "            # dimensions out = hidden layer size\n",
        "            layer = GCNConv(self.num_hidden, self.num_hidden)\n",
        "\n",
        "        else:  # output layer\n",
        "            # dimensions in = hidden layer size\n",
        "            # dimensions out = output size\n",
        "            layer = GCNConv(self.num_hidden, self.num_classes)\n",
        "\n",
        "        layers.append(layer)\n",
        "\n",
        "    return nn.ModuleList(layers)\n",
        "\n",
        "class GCN_model(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.num_features = args.num_features\n",
        "        self.num_layers = args.num_layers\n",
        "        self.num_hidden = args.num_hidden\n",
        "        self.num_classes = args.num_classes\n",
        "        self.wd = args.wd\n",
        "        self.lr = args.lr\n",
        "        self.layers = make_layers(self)\n",
        "\n",
        "    def forward(self, x, edge_idx):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            # apply the convolutional layer\n",
        "            x = layer(x, edge_idx)\n",
        "\n",
        "            # Since I did not apply the activation function in the Layers array, I apply it using conditionals (to decide relu or softmax) here\n",
        "            if i != len(self.layers) - 1:\n",
        "                x = F.relu(x)\n",
        "            else:\n",
        "                x = F.log_softmax(x, dim = 1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "dL4DCdsG3ERt"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### main.py File ###\n",
        "\n",
        "def train(model, X, Y, data):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = model.lr, weight_decay = model.wd)\n",
        "    optimizer.zero_grad()\n",
        "    activations = model(X, data.edge_index)\n",
        "\n",
        "    # only calculate loss on train labels!!\n",
        "    loss = F.nll_loss(activations[train_mask], Y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def get_masked_acc(activations, y_true, mask):\n",
        "    length = activations[mask].shape[0]\n",
        "    correct = 0\n",
        "    for yhat, y in zip(activations[mask], y_true[mask]):\n",
        "        if torch.argmax(yhat) == y:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / length\n",
        "\n",
        "def get_accuracy(activations, y_true, data):\n",
        "    train_acc = get_masked_acc(activations, y_true, data.train_mask)\n",
        "    test_acc = get_masked_acc(activations, y_true, data.test_mask)\n",
        "    val_acc = get_masked_acc(activations, y_true, data.val_mask)\n",
        "    return train_acc, test_acc, val_acc\n",
        "\n",
        "def main():\n",
        "    # use gpu if possible (works most of the time here on colab)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    # get data\n",
        "    data = hd.to(device)\n",
        "    y = processed_y\n",
        "\n",
        "    # get preferences\n",
        "    args = Args()\n",
        "    args = add_data_features(args, data)\n",
        "\n",
        "\n",
        "    for run in range(args.runs):\n",
        "        # initialize model\n",
        "        model = GCN_model(args).to(device)\n",
        "        print(\"\\n------------ new model ------------\\n\")\n",
        "        for epoch in range(args.epochs):\n",
        "          # log loss every 50 steps\n",
        "            if epoch % 50 == 0 or epoch == args.epochs - 1:\n",
        "                model.eval()\n",
        "                activations = model(x, hd.edge_index)\n",
        "                loss = F.nll_loss(activations, y)\n",
        "                train_acc, test_acc, val_acc = get_accuracy(activations, y, data)\n",
        "                print(f\" Epoch: {epoch} | Total Loss: {loss} | Train Accuracy: {train_acc} | Test Accuracy: {test_acc} | Val Accuracy: {val_acc}\")\n",
        "\n",
        "            # backprop & update\n",
        "            train(model, x, y, data)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "6peLX-4x3E-3",
        "outputId": "cfb72a5c-9a4a-4fdc-f142-0c1fb4e9d7ab"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-edaf60eecccd>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-111-edaf60eecccd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# get preferences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_data_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-107-ff206c4cecdf>\u001b[0m in \u001b[0;36madd_data_features\u001b[0;34m(args, data)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_data_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}