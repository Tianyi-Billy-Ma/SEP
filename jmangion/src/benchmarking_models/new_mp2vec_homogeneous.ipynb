{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-JQyuM4cVm1",
        "outputId": "44bacb2e-4380-4a8c-fcff-5c409e8f1df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import copy\n",
        "from torch_geometric.datasets import AMiner\n",
        "from torch_geometric.nn import MetaPath2Vec"
      ],
      "metadata": {
        "id": "G5DCbGpjcntf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.root_dir = \"/content\"\n",
        "    self.data_dir = \"/content/data\"\n",
        "    self.epochs = 300\n",
        "    self.runs = 5\n",
        "    self.droput = 0.4\n",
        "    self.lr = 0.001\n",
        "    self.wd = 0.001\n",
        "    self.num_layers = 2\n",
        "    self.num_hidden = 256\n",
        "    self.num_features = 0 # placeholder\n",
        "    self.num_classes = 0 # placeholder\n",
        "\n",
        "def add_data_features(args, data):\n",
        "  args.num_features = data.x.shape[1]\n",
        "  args.num_classes = data.y.shape[0]\n",
        "  return args"
      ],
      "metadata": {
        "id": "Zp5J3lQyccU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Args()\n",
        "dataset = AMiner(root=args.root_dir)\n",
        "data = dataset[0]\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omFHnf1Oclu4",
        "outputId": "4b59dce5-bc67-451c-af09-3197605d5fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
            "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
            "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
            "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "new_data = copy.deepcopy(data)\n",
        "#print(new_data.edge_types)\n",
        "print(new_data.edge_types[0])\n",
        "\n",
        "\n",
        "print(data.edge_index_dict)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f6r6BCyMfLiP",
        "outputId": "1286dd45-8894-4d2d-e9f3-0e5aa5d19eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnew_data = copy.deepcopy(data)\\n#print(new_data.edge_types)\\nprint(new_data.edge_types[0])\\n\\n\\nprint(data.edge_index_dict)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # We can see by addition that all the edges are now in the same dict, so we add that dict to the new data\n",
        "def make_homogeneous(data, new_data):\n",
        "    all_edges = torch.hstack((data.edge_index_dict[data.edge_types[0]], data.edge_index_dict[data.edge_types[1]], data.edge_index_dict[data.edge_types[2]], data.edge_index_dict[data.edge_types[3]]))\n",
        "    print(f\"Shape of new edges: {all_edges.shape}\")\n",
        "    print(\"Shapes of old edges add to new shape: \")\n",
        "    print(data.edge_index_dict[data.edge_types[0]].shape)\n",
        "    print(data.edge_index_dict[data.edge_types[1]].shape)\n",
        "    print(data.edge_index_dict[data.edge_types[2]].shape)\n",
        "    print(data.edge_index_dict[data.edge_types[3]].shape)\n",
        "    print()\n",
        "\n",
        "    print(\"Deleting original edges...\")\n",
        "    for edge_type in new_data.edge_types:\n",
        "        success = new_data.remove_edge_index(edge_type=edge_type, layout='coo')\n",
        "        if success:\n",
        "            print(f\"Successfully removed edge index for {edge_type}\")\n",
        "        else:\n",
        "            print(f\"Failed to remove edge index for {edge_type}\")\n",
        "\n",
        "    del(new_data['paper', 'written_by', 'author'])\n",
        "    del(new_data['author', 'writes', 'paper'])\n",
        "    del(new_data['paper', 'published_in', 'venue'])\n",
        "    del(new_data['venue', 'publishes', 'paper'])\n",
        "\n",
        "    print(f\"new_data has old edges removed: {new_data}\")\n",
        "    print(\"Adding new edges...\")\n",
        "    new_data.edge_index_dict = all_edges\n",
        "    print(f\"Resulting Data Structure: {new_data}\")\n"
      ],
      "metadata": {
        "id": "XtEyIDwrh4VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_homogeneous() method seems to double the connections but when I only pick one sided connections I get an error...\n",
        "#make_homogeneous(data, new_data)"
      ],
      "metadata": {
        "id": "D-JjyPyKopH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "homogeneous_data = data.to_homogeneous()"
      ],
      "metadata": {
        "id": "Dik9ghBlr4HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "homogeneous_data.edge_index_dict = {('node_type', 'edge_type', 'node_type') : homogeneous_data.edge_index}"
      ],
      "metadata": {
        "id": "AsXDp6dSuK8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "homogeneous_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmJhSmFzQXyh",
        "outputId": "991fd692-9c6c-4646-80e9-af3a1d9d3530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(\n",
              "  edge_index=[2, 25036020],\n",
              "  y=[3441217],\n",
              "  y_index=[3441217],\n",
              "  node_type=[4891819],\n",
              "  edge_type=[25036020],\n",
              "  edge_index_dict={ (node_type, edge_type, node_type)=[2, 25036020] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MetaPath2Vec\n",
        "\n",
        "# defining all 'metapaths' as tuples\n",
        "metapath = [\n",
        "    ('node_type', 'edge_type', 'node_type')\n",
        "]\n",
        "\n",
        "# select device and display it to user\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"DEVICE USED IN THIS SESSION: {device}\")\n",
        "\n",
        "\n",
        "model = MetaPath2Vec(homogeneous_data.edge_index_dict, embedding_dim=128,\n",
        "                     metapath=metapath, walk_length=50, context_size=7,\n",
        "                     walks_per_node=5, num_negative_samples=5,\n",
        "                     sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=2)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n",
        "\n",
        "def train(epoch, log_steps=100, eval_steps=2000):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for i, (pos_rw, neg_rw) in enumerate(iter(loader)):\n",
        "        #print(pos_rw.shape)\n",
        "        #print(neg_rw.shape)\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % log_steps == 0:\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
        "            total_loss = 0\n",
        "\n",
        "        if (i + 1) % eval_steps == 0:\n",
        "            acc = train_acc()\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Acc: {acc:.4f}'))\n",
        "\n",
        "\n",
        "def train_acc(train_ratio=0.1):\n",
        "    model.eval()\n",
        "\n",
        "    z = model('node_type', batch=data['author'].y_index.to(device))\n",
        "    y = data['author'].y\n",
        "\n",
        "    perm = torch.randperm(z.size(0))\n",
        "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
        "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
        "\n",
        "    return model.test(z[train_perm], y[train_perm], z[test_perm], y[test_perm],\n",
        "                      max_iter=150)\n",
        "\n",
        "def test_acc(train_ratio = 0.1):\n",
        "    model.eval()\n",
        "    z = model('node_type', batch=data['author'].y_index.to(device))\n",
        "    y = data['author'].y\n",
        "\n",
        "    perm = torch.randperm(z.size(0))\n",
        "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
        "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
        "\n",
        "    return model.test(z[test_perm], y[test_perm], z[test_perm], y[test_perm],\n",
        "                      max_iter=150)\n",
        "\n",
        "\n",
        "for epoch in range(1, 5):\n",
        "  train(epoch)\n",
        "  print(f\"Epoch: {epoch} | Train Accuracy: {train_acc():.4f} | Test Accuracy: {test_acc():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8oxw0FfdsbWe",
        "outputId": "29dc419c-7846-4001-d2e6-3a55869d08f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE USED IN THIS SESSION: cuda\n",
            "Epoch: 1, Step: 00100/38218, Loss: 9.6198\n",
            "Epoch: 1, Step: 00200/38218, Loss: 9.2327\n",
            "Epoch: 1, Step: 00300/38218, Loss: 8.7798\n",
            "Epoch: 1, Step: 00400/38218, Loss: 8.3400\n",
            "Epoch: 1, Step: 00500/38218, Loss: 7.9299\n",
            "Epoch: 1, Step: 00600/38218, Loss: 7.5603\n",
            "Epoch: 1, Step: 00700/38218, Loss: 7.2234\n",
            "Epoch: 1, Step: 00800/38218, Loss: 6.9146\n",
            "Epoch: 1, Step: 00900/38218, Loss: 6.6357\n",
            "Epoch: 1, Step: 01000/38218, Loss: 6.3699\n",
            "Epoch: 1, Step: 01100/38218, Loss: 6.1310\n",
            "Epoch: 1, Step: 01200/38218, Loss: 5.9049\n",
            "Epoch: 1, Step: 01300/38218, Loss: 5.6961\n",
            "Epoch: 1, Step: 01400/38218, Loss: 5.4982\n",
            "Epoch: 1, Step: 01500/38218, Loss: 5.3116\n",
            "Epoch: 1, Step: 01600/38218, Loss: 5.1362\n",
            "Epoch: 1, Step: 01700/38218, Loss: 4.9723\n",
            "Epoch: 1, Step: 01800/38218, Loss: 4.8169\n",
            "Epoch: 1, Step: 01900/38218, Loss: 4.6654\n",
            "Epoch: 1, Step: 02000/38218, Loss: 4.5223\n",
            "Epoch: 1, Step: 02000/38218, Acc: 0.2765\n",
            "Epoch: 1, Step: 02100/38218, Loss: 4.3881\n",
            "Epoch: 1, Step: 02200/38218, Loss: 4.2603\n",
            "Epoch: 1, Step: 02300/38218, Loss: 4.1365\n",
            "Epoch: 1, Step: 02400/38218, Loss: 4.0182\n",
            "Epoch: 1, Step: 02500/38218, Loss: 3.9041\n",
            "Epoch: 1, Step: 02600/38218, Loss: 3.7983\n",
            "Epoch: 1, Step: 02700/38218, Loss: 3.6962\n",
            "Epoch: 1, Step: 02800/38218, Loss: 3.5976\n",
            "Epoch: 1, Step: 02900/38218, Loss: 3.5043\n",
            "Epoch: 1, Step: 03000/38218, Loss: 3.4134\n",
            "Epoch: 1, Step: 03100/38218, Loss: 3.3262\n",
            "Epoch: 1, Step: 03200/38218, Loss: 3.2430\n",
            "Epoch: 1, Step: 03300/38218, Loss: 3.1640\n",
            "Epoch: 1, Step: 03400/38218, Loss: 3.0885\n",
            "Epoch: 1, Step: 03500/38218, Loss: 3.0141\n",
            "Epoch: 1, Step: 03600/38218, Loss: 2.9433\n",
            "Epoch: 1, Step: 03700/38218, Loss: 2.8772\n",
            "Epoch: 1, Step: 03800/38218, Loss: 2.8095\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2dc5ac47c7f8>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch} | Train Accuracy: {train_acc():.4f} | Test Accuracy: {test_acc():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-2dc5ac47c7f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_steps, eval_steps)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}