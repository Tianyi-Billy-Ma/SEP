{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "GyJdorM9usM_"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric > /dev/null\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import DBLP\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from torch_geometric.utils import to_torch_sparse_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "PoFVwJW_vEML"
      },
      "outputs": [],
      "source": [
        "### arguments.py File ###\n",
        "### Modified for colab since colab does not seem to like argparse ###\n",
        "\n",
        "# Defined custom class to hold arguments\n",
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.root_dir = \"/content\"\n",
        "    self.data_dir = \"/content/data\"\n",
        "    self.epochs = 300\n",
        "    self.runs = 5\n",
        "    self.droput = 0.4\n",
        "    self.lr = 0.001\n",
        "    self.wd = 0.001\n",
        "    self.num_layers = 2\n",
        "    self.num_hidden = 256\n",
        "    self.num_features = 0 # placeholder\n",
        "    self.num_classes = 0 # placeholder\n",
        "\n",
        "def add_data_features(args, data):\n",
        "  args.num_features = data.x.shape[1]\n",
        "  args.num_classes = data.y.shape[0]\n",
        "  return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "hYtRO0D_u4MI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e55247f-96f6-41fe-a18b-d2d50f7404a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  author={\n",
            "    x=[4057, 334],\n",
            "    y=[4057],\n",
            "    train_mask=[4057],\n",
            "    val_mask=[4057],\n",
            "    test_mask=[4057],\n",
            "  },\n",
            "  paper={ x=[14328, 4231] },\n",
            "  term={ x=[7723, 50] },\n",
            "  conference={ num_nodes=20 },\n",
            "  (author, to, paper)={ edge_index=[2, 19645] },\n",
            "  (paper, to, author)={ edge_index=[2, 19645] },\n",
            "  (paper, to, term)={ edge_index=[2, 85810] },\n",
            "  (paper, to, conference)={ edge_index=[2, 14328] },\n",
            "  (term, to, paper)={ edge_index=[2, 85810] },\n",
            "  (conference, to, paper)={ edge_index=[2, 14328] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "### data.py File ###\n",
        "args = Args()\n",
        "dataset = DBLP(root=args.root_dir)\n",
        "data = dataset[0]\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "gfm8XZGF8spv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23cb82aa-a601-4f00-fbc0-77a903e73971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['author', 'paper', 'term', 'conference']\n",
            "[('author', 'to', 'paper'), ('paper', 'to', 'author'), ('paper', 'to', 'term'), ('paper', 'to', 'conference'), ('term', 'to', 'paper'), ('conference', 'to', 'paper')]\n"
          ]
        }
      ],
      "source": [
        "# Printing the data's node and edge types\n",
        "for item in data.metadata():\n",
        "  print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Three Sets of Metapaths"
      ],
      "metadata": {
        "id": "9MexOuxZAmFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating (Author -> Paper -> Author) Metapaths\n",
        "\"\"\"\n",
        "1. Collect edge indices for author->paper and paper->author\n",
        "2. Convert edge indices to torch sparse tensors\n",
        "3. Matrix multiply ap_dense and pa_dense to get apa_dense\n",
        "4. Bring apa_dense back down to sparse and set all nonzero values to 1 to represent connections\n",
        "\"\"\"\n",
        "# 1\n",
        "num_authors = data[\"author\"].x.shape[0]\n",
        "num_papers = data[\"paper\"].x.shape[0]\n",
        "ap = data[('author', 'to', 'paper')].edge_index\n",
        "pa = ap.T\n",
        "# 2\n",
        "ap_dense_adj = to_torch_sparse_tensor(ap, size=(num_authors, num_papers))\n",
        "pa_dense_adj = ap_dense_adj.T\n",
        "print(type(ap), ap)\n",
        "print()\n",
        "print(type(ap_dense_adj), ap_dense_adj)\n",
        "print()\n",
        "print(f\"matrices to be multiplied: {list(ap_dense_adj.shape)}, {list(pa_dense_adj.shape)}\") # will end up being a 4057 x 4057 matrix bc it will have all mps starting and ending with author, that go through a paper\n",
        "# 3\n",
        "apa_dense_adj = ap_dense_adj @ pa_dense_adj\n",
        "apa_dense_adj\n",
        "# 4\n",
        "apa_sparse_adj = apa_dense_adj.indices().to_sparse().coalesce()\n",
        "apa_sparse_adj.indices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDAua4yRBmna",
        "outputId": "cfc80725-05a1-4318-87fb-95fc8bc98b73"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> tensor([[    0,     0,     1,  ...,  4054,  4055,  4056],\n",
            "        [ 2364,  6457,  2365,  ..., 13891, 13891, 13892]])\n",
            "\n",
            "<class 'torch.Tensor'> tensor(indices=tensor([[    0,     0,     1,  ...,  4054,  4055,  4056],\n",
            "                       [ 2364,  6457,  2365,  ..., 13891, 13891, 13892]]),\n",
            "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
            "       size=(4057, 14328), nnz=19645, layout=torch.sparse_coo)\n",
            "\n",
            "matrices to be multiplied: [4057, 14328], [14328, 4057]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0,     0,     0,  ...,     1,     1,     1],\n",
              "        [    1,     2,     3,  ..., 11110, 11111, 11112]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating (Author -> Paper -> Conference -> Paper -> Author) Metapaths\n",
        "\"\"\"\n",
        "1. Collect edge indices for (author->paper) (paper->conference) (conference->paper) (paper->author)\n",
        "2. Convert edge indices to torch sparse tensors\n",
        "3. Multiply edge indices from (Author -> Paper -> Conference) and (Conference -> Paper -> Author) -- this should be author x author in size\n",
        "4. Bring apcpa back down to sparse and set all nonzero values to 1 to represent connections\n",
        "\"\"\"\n",
        "# 1.\n",
        "num_conferences = data[\"conference\"].num_nodes\n",
        "pc = data[('paper', 'to', 'conference')].edge_index\n",
        "# 2.\n",
        "pc_dense_adj = to_torch_sparse_tensor(pc, size=(num_papers, num_conferences))\n",
        "# 3.\n",
        "print(f\"Multiplying: apc = {list(ap_dense_adj.shape)}, {list(pc_dense_adj.shape)} which yields a num_authors ({num_authors}) by num_conferences ({num_conferences}) matrix\")\n",
        "apc_dense_adj = ap_dense_adj @ pc_dense_adj\n",
        "print(f\"multiplying apc with its transpose to obtain apcpa which is shape (author x author) ie ({num_authors} x {num_authors})\")\n",
        "apcpa_dense_adj = apc_dense_adj @ apc_dense_adj.T\n",
        "# 4.\n",
        "apcpa_sparse_adj = apcpa_dense_adj.indices().to_sparse().coalesce()\n",
        "apcpa_sparse_adj.indices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKcg-uMK2NP9",
        "outputId": "bdbae8ff-0949-42fa-cb7c-a3a4474eec69"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiplying: apc = [4057, 14328], [14328, 20] which yields a num_authors (4057) by num_conferences (20) matrix\n",
            "multiplying apc with its transpose to obtain apcpa which is shape (author x author) ie (4057 x 4057)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[      0,       0,       0,  ...,       1,       1,       1],\n",
              "        [   1037,    1038,    1039,  ..., 5000492, 5000493, 5000494]])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating (Author -> Paper -> Term -> Paper -> Author) Metapaths\n",
        "\"\"\"\n",
        "1. Collect edge indices for (author->paper) (paper->term) (term->paper) (paper->author)\n",
        "2. Convert edge indices to torch sparse tensors\n",
        "3. Multiply edge indices from (Author -> Paper -> Term) and (Term -> Paper -> Author) -- this should be author x author in size\n",
        "4. Bring aptpa back down to sparse and set all nonzero values to 1 to represent connections\n",
        "\"\"\"\n",
        "# 1.\n",
        "num_terms = data[\"term\"].x.shape[0]\n",
        "pt = data[('paper', 'to', 'term')].edge_index\n",
        "# 2.\n",
        "pt_dense_adj = to_torch_sparse_tensor(pt, size=(num_papers, num_terms))\n",
        "# 3.\n",
        "print(f\"Multiplying: apt = {list(ap_dense_adj.shape)}, {list(pt_dense_adj.shape)} which yields a num_authors ({num_authors}) by num_conferences ({num_terms}) matrix\")\n",
        "apt_dense_adj = ap_dense_adj @ pt_dense_adj\n",
        "print(f\"multiplying apc with its transpose to obtain apcpa which is shape (author x author) ie ({num_authors} x {num_authors})\")\n",
        "aptpa_dense_adj = apt_dense_adj @ apt_dense_adj.T\n",
        "# 4.\n",
        "aptpa_sparse_adj = aptpa_dense_adj.indices().to_sparse().coalesce()\n",
        "aptpa_sparse_adj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2K3qUAAb3q",
        "outputId": "13c2cc01-f051-4fdb-a1d2-ec3da5b1ed22"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiplying: apt = [4057, 14328], [14328, 7723] which yields a num_authors (4057) by num_conferences (7723) matrix\n",
            "multiplying apc with its transpose to obtain apcpa which is shape (author x author) ie (4057 x 4057)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(indices=tensor([[      0,       0,       0,  ...,       1,       1,\n",
              "                              1],\n",
              "                       [   1339,    1340,    1341,  ..., 7043568, 7043569,\n",
              "                        7043570]]),\n",
              "       values=tensor([   1,    1,    1,  ..., 4043, 4045, 4056]),\n",
              "       size=(2, 7043571), nnz=14084464, layout=torch.sparse_coo)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(aptpa_sparse_adj.indices()[0].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2attD8CGESfk",
        "outputId": "cfacdcb7-dd1c-405d-8268-826063317ecc"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring the metapaths\n",
        "num_apa = (apa_dense_adj.to_dense() == 1).sum().item()\n",
        "num_apcpa = (apcpa_dense_adj.to_dense() == 1).sum().item()\n",
        "num_aptpa = (aptpa_dense_adj.to_dense() == 1).sum().item()\n",
        "print(num_apa, num_apcpa, num_aptpa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ-gMqU5BxZJ",
        "outputId": "24965195-66fa-406d-8960-ce62b6f26d73"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5615 1568211 2527692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting the Metapaths into Usable Datasets"
      ],
      "metadata": {
        "id": "APTlgGcqC9of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the apa dataset\n",
        "\n",
        "apa_data = torch_geometric.data.HeteroData()\n",
        "apa_data[\"author\"].x = [author for author in data[\"author\"].x if author in ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG5NzJ0pDPDk",
        "outputId": "9d249e8e-79e0-42a4-ea10-7a7bb17bba3e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "hi2-fCM6movf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8e20af-dd4e-47a5-c999-0095a0eec514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original (heterogeneous) dataset summary: \n",
            "HeteroData(\n",
            "  author={\n",
            "    x=[4057, 334],\n",
            "    y=[4057],\n",
            "    train_mask=[4057],\n",
            "    val_mask=[4057],\n",
            "    test_mask=[4057],\n",
            "  },\n",
            "  paper={ x=[14328, 4231] },\n",
            "  term={ x=[7723, 50] },\n",
            "  conference={ num_nodes=20 },\n",
            "  (author, to, paper)={ edge_index=[2, 19645] },\n",
            "  (paper, to, author)={ edge_index=[2, 19645] },\n",
            "  (paper, to, term)={ edge_index=[2, 85810] },\n",
            "  (paper, to, conference)={ edge_index=[2, 14328] },\n",
            "  (term, to, paper)={ edge_index=[2, 85810] },\n",
            "  (conference, to, paper)={ edge_index=[2, 14328] }\n",
            ")\n",
            "\n",
            " --------------- \n",
            "\n",
            "New (homogeneous) dataset summary: \n",
            "Data(edge_index=[2, 239566], y=[26128], train_mask=[26128], val_mask=[26128], test_mask=[26128], node_type=[26128], edge_type=[239566])\n"
          ]
        }
      ],
      "source": [
        "### Data Modification (heterogeneous --> homogeneous)\n",
        "print(\"Original (heterogeneous) dataset summary: \")\n",
        "print(data)\n",
        "print(\"\\n --------------- \\n\")\n",
        "hd = data.to_homogeneous()\n",
        "print(\"New (homogeneous) dataset summary: \")\n",
        "print(hd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyIrKRFfvT6C"
      },
      "outputs": [],
      "source": [
        "### model.py File ###\n",
        "\n",
        "def make_layers(self):\n",
        "    layers = []\n",
        "    # initialize layers in a loop that uses conditionals to determine the input and output dimensions of the feature vectors\n",
        "    for i in range(self.num_layers):\n",
        "        if i == 0:  # first layer\n",
        "            # dimensions in = input data size\n",
        "            # dimensions out = hidden layer size\n",
        "            layer = GCNConv(self.num_features, self.num_hidden)\n",
        "\n",
        "        elif i < self.num_layers - 1: # hidden layer(s)\n",
        "            # dimensions in = hidden layer size\n",
        "            # dimensions out = hidden layer size\n",
        "            layer = GCNConv(self.num_hidden, self.num_hidden)\n",
        "\n",
        "        else:  # output layer\n",
        "            # dimensions in = hidden layer size\n",
        "            # dimensions out = output size\n",
        "            layer = GCNConv(self.num_hidden, self.num_classes)\n",
        "\n",
        "        layers.append(layer)\n",
        "\n",
        "    return nn.ModuleList(layers)\n",
        "\n",
        "class GCN_model(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.num_features = args.num_features\n",
        "        self.num_layers = args.num_layers\n",
        "        self.num_hidden = args.num_hidden\n",
        "        self.num_classes = args.num_classes\n",
        "        self.wd = args.wd\n",
        "        self.lr = args.lr\n",
        "        self.layers = make_layers(self)\n",
        "\n",
        "    def forward(self, x, edge_idx):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            # apply the convolutional layer\n",
        "            x = layer(x, edge_idx)\n",
        "\n",
        "            # Since I did not apply the activation function in the Layers array, I apply it using conditionals (to decide relu or softmax) here\n",
        "            if i != len(self.layers) - 1:\n",
        "                x = F.relu(x)\n",
        "            else:\n",
        "                x = F.log_softmax(x, dim = 1)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c8qFCbQuntx"
      },
      "outputs": [],
      "source": [
        "### main.py File ###\n",
        "\n",
        "def train(model, X, Y, data):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = model.lr, weight_decay = model.wd)\n",
        "    optimizer.zero_grad()\n",
        "    activations = model(X, data.edge_index)\n",
        "\n",
        "    # only calculate loss on train labels!!\n",
        "    loss = F.nll_loss(activations[data.train_mask], Y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def get_masked_acc(activations, y_true, mask):\n",
        "    length = activations[mask].shape[0]\n",
        "    correct = 0\n",
        "    for yhat, y in zip(activations[mask], y_true[mask]):\n",
        "        if torch.argmax(yhat) == y:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / length\n",
        "\n",
        "def get_accuracy(activations, y_true, data):\n",
        "    train_acc = get_masked_acc(activations, y_true, data.train_mask)\n",
        "    test_acc = get_masked_acc(activations, y_true, data.test_mask)\n",
        "    val_acc = get_masked_acc(activations, y_true, data.val_mask)\n",
        "    return train_acc, test_acc, val_acc\n",
        "\n",
        "def main():\n",
        "    # use gpu if possible (works most of the time here on colab)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    # get data\n",
        "    data = dataset[0].to(device)\n",
        "    x = data.x\n",
        "    y = data.y\n",
        "\n",
        "    # get preferences\n",
        "    args = Args()\n",
        "    args = add_data_features(args, data)\n",
        "\n",
        "\n",
        "    for run in range(args.runs):\n",
        "        # initialize model\n",
        "        model = GCN_model(args).to(device)\n",
        "        print(\"\\n------------ new model ------------\\n\")\n",
        "        for epoch in range(args.epochs):\n",
        "          # log loss every 50 steps\n",
        "            if epoch % 50 == 0 or epoch == args.epochs - 1:\n",
        "                model.eval()\n",
        "                activations = model(x, data.edge_index)\n",
        "                loss = F.nll_loss(activations, y)\n",
        "                train_acc, test_acc, val_acc = get_accuracy(activations, y, data)\n",
        "                print(f\" Epoch: {epoch} | Total Loss: {loss} | Train Accuracy: {train_acc} | Test Accuracy: {test_acc} | Val Accuracy: {val_acc}\")\n",
        "\n",
        "            # backprop & update\n",
        "            train(model, x, y, data)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}