{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twikit import Client, TooManyRequests\n",
    "from account_info import USERNAME, EMAIL, PASSWORD\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib.request\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Initialize client\n",
    "client = Client('en-US')\n",
    "\n",
    "client.login(\n",
    "    auth_info_1=USERNAME ,\n",
    "    auth_info_2=EMAIL,\n",
    "    password=PASSWORD\n",
    ")\n",
    "\n",
    "# save cookies in order to pull data without getting banned\n",
    "client.save_cookies('cookies.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the cookies that were saved\n",
    "client.load_cookies('cookies.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_list = []\n",
    "\n",
    "# all the file paths for all the structures in the end \n",
    "save_path_list.append(r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\data\\data_for_twitter\\data_structures\\user_structure.json')\n",
    "save_path_list.append(r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\data\\data_for_twitter\\data_structures\\post_structure.json')\n",
    "save_path_list.append(r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\data\\data_for_twitter\\data_structures\\comment_structure.json')\n",
    "save_path_list.append(r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\data\\data_for_twitter\\data_structures\\picture_strucutre.json')\n",
    "save_path_list.append(r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\data\\data_for_twitter\\data_structures\\keyword_structure.json')\n",
    "save_path_list.append(r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\data\\data_for_twitter\\data_structures\\relation_structure.json')\n",
    "\n",
    "# file path to excel sheet\n",
    "file_path_to_excel = r\"C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\codes.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(URL, save_as):\n",
    "    '''Function uses image URL and saves the image onto the desired path and file type'''\n",
    "    urllib.request.urlretrieve(URL,save_as)\n",
    "\n",
    "\n",
    "def delete_jpg(file):\n",
    "    '''This file takes in the file path and deletes it.'''\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "    else:\n",
    "        print('File not found')\n",
    "\n",
    "\n",
    "# this saves the json file on the described directory \n",
    "def save_json(file, file_path):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(file, f,indent=4)\n",
    "\n",
    "\n",
    "def open_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data \n",
    "\n",
    "\n",
    "def retry_on_rate_limit_error(func, *args, **kwargs):\n",
    "    max_retries = 5\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except TooManyRequests as e:\n",
    "            print(\"Rate limit exceed trying again in 60 sec\")\n",
    "            time.sleep(60)\n",
    "            retries += 1\n",
    "    raise Exception(\"Max tries reached\")\n",
    "\n",
    "\n",
    "def keywords_to_dict(file_path =r\"C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\codes.xlsx\" ):\n",
    "    '''This function takes in the excel sheet that has keywords and its ids split up into columns.\n",
    "    Then it creates two dictionaries, keyname and keyname_id. The values are numbered 0 to the \n",
    "    length of the columns. Once created they return these dictionaries.'''\n",
    "\n",
    "    # reads in excel sheet into pandas data frame\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # this turns the street name and its code name into list \n",
    "    street_name_list = df['keyname'].astype(str).values.tolist()\n",
    "    street_name_code_list = df['keyname_id'].astype(str).values.tolist()\n",
    "\n",
    "    # this dictionary contains the keyname in the keys and keyname id in values\n",
    "    keyname = {}\n",
    "    keyname_id = {}\n",
    "    for i in range(26):\n",
    "        keyname[i] = street_name_list[i]\n",
    "        keyname_id[i] = street_name_code_list[i]\n",
    "        \n",
    "    return keyname, keyname_id\n",
    "\n",
    "\n",
    "def keyword_search_in_users(keyname_to_search, list_of_users, list_to_append, keywords_dict, iteration):\n",
    "    \"\"\"This function takes in a keyname to search a list of users. It will search the users name,\n",
    "    keyname, description and tweets for the keyname. If it finds it on the tweets it appends\n",
    "    to the list_to_append\"\"\"\n",
    "\n",
    "    keynames, keyname_ids = keywords_to_dict()\n",
    "    keyword_id = keyname_ids[iteration]\n",
    "    # gets a user from the list_of_users and goes through their name, screen name \n",
    "    # and description to find keywords. If they find one they append the user to the list]\n",
    "    \n",
    "    for user in list_of_users:\n",
    "        if len(list_to_append) == 30:\n",
    "            break\n",
    "        else: \n",
    "            if keyname_to_search in user.name:\n",
    "                keywords_dict[keyword_id][\"ids\"].append('user_'+ str(user.id))\n",
    "                list_to_append.append('user_' +  user.id)\n",
    "\n",
    "            elif keyname_to_search in user.screen_name:\n",
    "                keywords_dict[keyword_id][\"ids\"].append('user_'+ str(user.id))\n",
    "                list_to_append.append('user_' + user.id)\n",
    "\n",
    "            elif keyname_to_search in user.description:\n",
    "                keywords_dict[keyword_id][\"ids\"].append('user_'+ str(user.id))\n",
    "                list_to_append.append('user_' + user.id)\n",
    "\n",
    "    return list_to_append, keywords_dict\n",
    "\n",
    "\n",
    "def keyword_search_in_tweets(tweet):\n",
    "    \"\"\"This function takes in tweets, keyname, and keyname ids. Then \n",
    "    it goes thourgh the keynames and trys to find it in the text of the \n",
    "    tweet. If it finds it appends it to a list and at the end it returns this\n",
    "    list.\"\"\"\n",
    "\n",
    "    keyname, keyname_id = keywords_to_dict()\n",
    "    keyname_found_in_tweet = []\n",
    "\n",
    "    # find keyword in tweet text, if so append to list\n",
    "    for keys, keyword in keyname.items():\n",
    "        if keyword in tweet.full_text:\n",
    "            keyname_found_in_tweet.append(keyname_id[keys])\n",
    "    \n",
    "    return keyname_found_in_tweet\n",
    "\n",
    "\n",
    "def relations_in_comments(tweet, reply, relations):\n",
    "            \n",
    "            Relation_Structure = {\n",
    "                \"src_id\": 'tweet_' + str(reply.id),\n",
    "                \"relation\": 'comment-under-post',\n",
    "                \"dest_id\": 'tweet_' + str(tweet.id)\n",
    "            }\n",
    "\n",
    "            reply_user = reply.user\n",
    "            relations.append(Relation_Structure)\n",
    "\n",
    "            Relation_Structure = {\n",
    "                \"src_id\": 'user_' + str(reply_user.id),\n",
    "                \"relation\": 'user-make-comment',\n",
    "                \"dest_id\": 'tweet_' + str(reply.id)\n",
    "            }\n",
    "\n",
    "            relations.append(Relation_Structure)\n",
    "\n",
    "            keywords, keywords_ids = keywords_to_dict()\n",
    "\n",
    "            for key, keyname in keywords.items():\n",
    "                if keyname in reply.full_text:\n",
    "                    Relation_Structure = {\n",
    "                        \"src_id\": 'tweet_' + str(reply.id),\n",
    "                        \"relation\": 'comment-contain-keyword',\n",
    "                        \"dest_id\": keywords_ids[key]\n",
    "                    }\n",
    "\n",
    "                    relations.append(Relation_Structure)\n",
    "            return relations\n",
    "\n",
    "\n",
    "def remove_duplicates_from_list(list):\n",
    "    \"\"\"This functions removes duplicates from list\"\"\"\n",
    "    result = []\n",
    "    for item in list:\n",
    "        if item not in result:\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def tweet_mentions_user(user, tweet, relations):\n",
    "    \"\"\"This function is for when a user mentions another user in a tweet. Finds \n",
    "    mentioned users user_name and adds the relation_structure to relations.\"\"\"\n",
    "\n",
    "    mentions = re.findall(r'@(\\S+)', tweet.full_text)\n",
    "    mentions = remove_duplicates_from_list(mentions)\n",
    "    for mention in mentions:\n",
    "        try:\n",
    "            mentioned_user = client.get_user_by_screen_name(mention)\n",
    "            Relation_Structure = {\n",
    "                \"src_id\": 'user_' + str(user.id),\n",
    "                \"relation\": 'user-mention/tag-user',\n",
    "                \"dest_id\": 'user_' + str(mentioned_user.id)\n",
    "            }\n",
    "\n",
    "            relations.append(Relation_Structure)\n",
    "        except:\n",
    "            pass\n",
    "    return relations \n",
    "\n",
    "\n",
    "def extract_tweet_picture_structure(user, tweet, pic_id_starter, relations):\n",
    "    \"\"\"This function takes in the type user and tweet. Then goes down the post\n",
    "    structure sorting out the data. Finally it returns the post_structure\"\"\"\n",
    "    \n",
    "    if '@' in tweet.full_text:\n",
    "        relations = tweet_mentions_user(user, tweet, relations)\n",
    "\n",
    "    # retrieve keywords found in tweet\n",
    "    keyname_found = keyword_search_in_tweets(tweet)\n",
    "    # construct post structure\n",
    "    favoriters = tweet.get_favoriters(20)\n",
    "\n",
    "    Relation_Structure = {\n",
    "            \"src_id\": 'user_' + str(user.id),\n",
    "            \"relation\": 'user-publish-post',\n",
    "            \"dest_id\": 'tweet_' + str(tweet.id)\n",
    "        }\n",
    "\n",
    "    relations.append(Relation_Structure)\n",
    "\n",
    "    Post_Structure = {\n",
    "        \"user_id\": 'user_' + str(user.id),\n",
    "        \"post_id\": 'tweet_' + str(tweet.id),\n",
    "        \"user_comment\": tweet.full_text,\n",
    "        \"pic_id\": \"\",\n",
    "        \"liked_users\": [ 'user_' + str(favoriter.id) for favoriter in favoriters],\n",
    "        \"comments\": '',\n",
    "        \"keywords\": keyname_found,\n",
    "    }\n",
    "\n",
    "    tweet = client.get_tweet_by_id(tweet.id)\n",
    "    replies = tweet.replies\n",
    "    if replies:\n",
    "        Post_Structure[\"comments\"] = [f'tweet_{reply.id}' for reply in replies]\n",
    "        \n",
    "        for reply in replies:\n",
    "            relations = relations_in_comments(tweet, reply, relations)\n",
    "            \n",
    "    for favoriter in favoriters:\n",
    "        Relation_Structure = {\n",
    "                \"src_id\": 'user_' + str(favoriter.id),\n",
    "                \"relation\": 'user-like-post',\n",
    "                \"dest_id\": 'tweet_' + str(tweet.id)\n",
    "            }\n",
    "        \n",
    "        relations.append(Relation_Structure)\n",
    "         \n",
    "    media_data = tweet.media\n",
    "    if media_data:\n",
    "        Post_Structure[\"pic_id\"] = 'pic_' + str(pic_id_starter)\n",
    "\n",
    "        Picture_Structure = {\n",
    "            \"pic_id\": 'pic_' + str(pic_id_starter),\n",
    "            \"post_id\": 'tweet_' + str(tweet.id),\n",
    "            \"url\": media_data[0].get('media_url_https')\n",
    "        }\n",
    "\n",
    "        Relation_Structure = {\n",
    "                \"src_id\": 'tweet_' + str(tweet.id),\n",
    "                \"relation\": 'post-has-picture',\n",
    "                \"dest_id\": 'post_' + str(pic_id_starter)\n",
    "            }\n",
    "        \n",
    "        relations.append(Relation_Structure)\n",
    "        pic_id_starter += 1\n",
    "        return Post_Structure, Picture_Structure, pic_id_starter, relations\n",
    "    \n",
    "    else:\n",
    "        Picture_Structure = {}\n",
    "        return Post_Structure, Picture_Structure, pic_id_starter, relations\n",
    "\n",
    "\n",
    "def get_relations_followers_following(relations, followers_list, user):\n",
    "    '''This function gets the realtions between a user and it's\n",
    "    following/follower list'''\n",
    "\n",
    "    user_id = user.id\n",
    "    for follower in followers_list:\n",
    "        Relation_Structure = {\n",
    "                \"src_id\": follower,\n",
    "                \"relation\": 'user-follow/followed-user',\n",
    "                \"dest_id\": 'user_' + str(user_id)\n",
    "            }\n",
    "                \n",
    "        relations.append(Relation_Structure)\n",
    "    return relations\n",
    "    \n",
    "\n",
    "def realtion_in_profile(user, keyword_id, relations):\n",
    "    '''Finds the relations profile of users. If a keyword is found \n",
    "    in the profile it creates a relation structure for it.'''\n",
    "    Relation_Structure = {\n",
    "                \"src_id\": 'user_' + str(user.id),\n",
    "                \"relation\": 'user-profile-keyword',\n",
    "                \"dest_id\": keyword_id\n",
    "            }\n",
    "    relations.append(Relation_Structure)\n",
    "    return relations\n",
    "\n",
    "\n",
    "def realtion_keyword_in_tweet(tweet, keyword_id, relations):\n",
    "    '''Adds relation structure between post and keyword'''\n",
    "    Relation_Structure = {\n",
    "                \"src_id\": 'tweet_' + str(tweet.id),\n",
    "                \"relation\": 'post-include-keyword',\n",
    "                \"dest_id\": keyword_id,\n",
    "            }\n",
    "    relations.append(Relation_Structure)\n",
    "    return relations\n",
    "\n",
    "\n",
    "def add_followers_or_following(followers_list):\n",
    "    if len(followers_list) != 30:\n",
    "        for follower in followers:\n",
    "            if len(followers_list) == 30:\n",
    "                break\n",
    "            elif follower not in followers_list:\n",
    "                followers_list.append('user_' + follower.id)\n",
    "    return followers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all data structures \n",
    "users = {}\n",
    "posts = {}\n",
    "comments = {}\n",
    "pictures = {}\n",
    "keywords_dict = {}\n",
    "relations = []\n",
    "\n",
    "data_structures_to_save = [users,posts, comments, pictures, keywords_dict, relations]\n",
    "\n",
    "for i in range(len(save_path_list)):\n",
    "    save_json(data_structures_to_save[i], save_path_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16822\\miniconda3\\Lib\\site-packages\\twikit\\client.py:3084: UserWarning: Some followers are excluded because \"Quality Filter\" is enabled. To get all followers, turn off it in the Twitter settings.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m tweets \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mget_tweets(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweets\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# gets users followers returns a list of users, return user type \u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m followers \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_followers\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# gets users following returns a list of users, return user type\u001b[39;00m\n\u001b[0;32m     54\u001b[0m following \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mget_following(user\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[1;32mc:\\Users\\16822\\miniconda3\\Lib\\site-packages\\twikit\\user.py:300\u001b[0m, in \u001b[0;36mUser.get_followers\u001b[1;34m(self, count)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_followers\u001b[39m(\u001b[38;5;28mself\u001b[39m, count: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Result[User]:\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    Retrieves a list of followers for the user.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    Client.get_user_followers\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user_followers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16822\\miniconda3\\Lib\\site-packages\\twikit\\client.py:3159\u001b[0m, in \u001b[0;36mClient.get_user_followers\u001b[1;34m(self, user_id, count, cursor)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_user_followers\u001b[39m(\n\u001b[0;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m, user_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   3142\u001b[0m     count: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, cursor: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Result[User]:\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3145\u001b[0m \u001b[38;5;124;03m    Retrieves a list of followers for a given user.\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;124;03m        A list of User objects representing the followers.\u001b[39;00m\n\u001b[0;32m   3158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_user_friendship\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3160\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFOLLOWERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\n\u001b[0;32m   3164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16822\\miniconda3\\Lib\\site-packages\\twikit\\client.py:3077\u001b[0m, in \u001b[0;36mClient._get_user_friendship\u001b[1;34m(self, user_id, count, endpoint, cursor)\u001b[0m\n\u001b[0;32m   3067\u001b[0m params \u001b[38;5;241m=\u001b[39m flatten_params({\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: variables,\n\u001b[0;32m   3069\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: FEATURES\n\u001b[0;32m   3070\u001b[0m })\n\u001b[0;32m   3071\u001b[0m response, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   3072\u001b[0m     endpoint,\n\u001b[0;32m   3073\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m   3074\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_headers\n\u001b[0;32m   3075\u001b[0m )\n\u001b[1;32m-> 3077\u001b[0m items \u001b[38;5;241m=\u001b[39m \u001b[43mfind_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentries\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   3078\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3079\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "keyname, keyname_id = keywords_to_dict()\n",
    "search_key = keyname[0]\n",
    "# [0,13] words to search. \n",
    "user_keyword = retry_on_rate_limit_error(client.search_user,'Amphetamine', 100)\n",
    "\n",
    "# all data structures \n",
    "users = {}\n",
    "posts = {}\n",
    "comments = {}\n",
    "pictures = {}\n",
    "keywords_dict = {}\n",
    "relations = []\n",
    "\n",
    "key_structure_list = []\n",
    "for keys, keynames in keyname.items():\n",
    "    keyname_structure = {\n",
    "        \"keyword\": keynames,\n",
    "        \"keyword_id\": keyname_id[keys],\n",
    "        \"ids\": [],\n",
    "    }\n",
    "    keywords_dict[keyname_id[keys]] = keyname_structure\n",
    "    # key_structure_list.append(keyname_structure)\n",
    "\n",
    "pic_id_num_starter = 20000000000\n",
    "picture_id_dict = {}\n",
    "\n",
    "\n",
    "account_num = 1\n",
    "for user in user_keyword:\n",
    "    # users = {}\n",
    "    # posts = {}\n",
    "    # comments = {}\n",
    "    # pictures = {}\n",
    "    # keywords_dict = {}\n",
    "    # relations = []\n",
    "    # if account_num % 20 == 0:\n",
    "    #     print('sleeping')\n",
    "    #     time.sleep(600)\n",
    "\n",
    "    try: \n",
    "\n",
    "        keywords = []\n",
    "\n",
    "        # keyname contains the keynames and keyname_id contains their ids\n",
    "        keyname, keyname_id = keywords_to_dict()\n",
    "\n",
    "        # get the users tweets\n",
    "        tweets = user.get_tweets('tweets',15)\n",
    "\n",
    "        # gets users followers returns a list of users, return user type \n",
    "        followers = user.get_followers(user.id)\n",
    "\n",
    "        # gets users following returns a list of users, return user type\n",
    "        following = user.get_following(user.id)\n",
    "\n",
    "        \n",
    "        # empty list for the followers\n",
    "        followers_list = []\n",
    "        following_list = []\n",
    "\n",
    "        # add the user or their tweets to keyword_structure if a keyword is found\n",
    "        for i in range(len(keyname)):\n",
    "            keyword = keyname[i]\n",
    "            keyword_id = keyname_id[i]\n",
    "            if keyword in user.name:\n",
    "                keywords_dict[keyword_id][\"ids\"].append('user_'+ str(user.id))\n",
    "                relations = realtion_in_profile(user, keyword_id, relations)\n",
    "                keywords.append(keyword_id)\n",
    "            elif keyword in user.screen_name:\n",
    "                keywords_dict[keyword_id][\"ids\"].append('user_'+ str(user.id))\n",
    "                relations = realtion_in_profile(user, keyword_id, relations)\n",
    "                keywords.append(keyword_id)\n",
    "            elif keyword in user.description:\n",
    "                keywords_dict[keyword_id][\"ids\"].append('user_'+ str(user.id))\n",
    "                relations = realtion_in_profile(user, keyword_id, relations)\n",
    "                keywords.append(keyword_id)\n",
    "            for tweet in tweets:\n",
    "                if keyword in tweet.full_text:\n",
    "                    keywords_dict[keyword_id][\"ids\"].append('tweet_'+ str(tweet.id))\n",
    "                    relations = realtion_keyword_in_tweet(tweet, keyword_id, relations)\n",
    "                    keywords.append(keyword_id)\n",
    "\n",
    "        # go through the users tweets, description, name to find keywords\n",
    "        counter = 0\n",
    "        for keys, keyname in keyname.items():\n",
    "            # go through the users followers description, tweet, and names to \n",
    "            # see if it finds any keywords. If it does it adds them to the follower_list\n",
    "            followers_list, keywords_dict = keyword_search_in_users(keyname, followers, followers_list, keywords_dict, counter)\n",
    "\n",
    "            # Goes thorugh the users following description, tweet, and names to \n",
    "            # see if it finds any keywords. If it does it adds them to the following_list\n",
    "            following_list, keywords_dict= keyword_search_in_users(keyname, following, following_list, keywords_dict, counter)\n",
    "            counter += 1 \n",
    "\n",
    "        # ensure that if not followers or following where found through the keywords\n",
    "        # to add however many followers are left. \n",
    "        followers_list = add_followers_or_following(followers_list)\n",
    "        following_list = add_followers_or_following(following_list)\n",
    "\n",
    "        relations = get_relations_followers_following(relations, followers_list, user)\n",
    "        relations = get_relations_followers_following(relations,following_list, user)\n",
    "\n",
    "        # Structure to store the data\n",
    "        User_Structure = {\n",
    "            \"username\": user.screen_name,\n",
    "            \"user_id\": 'user_' + str(user.id), \n",
    "            \"followers\": followers_list,\n",
    "            \"followees\": following_list, #['user_' + str(followees_id) for followees_id in client.get_friends_ids(user.id,user.screen_name,30)]\n",
    "            \"profile_pic\": user.profile_image_url,\n",
    "            \"profile_text\": user.description,\n",
    "            \"posts\": ['tweet_' + tweet.id for tweet in tweets]  ,\n",
    "            \"keywords\": keywords\n",
    "        }\n",
    "        \n",
    "        # go through each tweet in users tweet \n",
    "        for tweet in tweets:\n",
    "            tweet_id_name = 'tweet_' + str(tweet.id)\n",
    "\n",
    "            # check to see if tweet id not in post_strucutre if not create one for the tweet\n",
    "            if tweet_id_name not in posts:\n",
    "\n",
    "                # extract the post structure form the tweet and comments \n",
    "                original_pic_id_num = pic_id_num_starter\n",
    "                post_structure, picture_structure, pic_id_num_starter, relations = extract_tweet_picture_structure(user, tweet, pic_id_num_starter, relations)\n",
    "                posts[tweet_id_name] = post_structure\n",
    "                if picture_structure:\n",
    "                    pictures['pic_' + str(original_pic_id_num)] = picture_structure\n",
    "\n",
    "            replies_in_post = post_structure['comments']\n",
    "            replies_in_post = [reply.replace('tweet_','') for reply in replies_in_post]\n",
    "            if replies_in_post:\n",
    "\n",
    "                for reply in replies_in_post:\n",
    "                    reply = client.get_tweet_by_id(reply)\n",
    "                    reply_id_name = 'tweet_' +str(reply.id)\n",
    "\n",
    "                    if reply_id_name not in posts:\n",
    "                        original_pic_id_num = pic_id_num_starter\n",
    "                        post_structure, picture_structure, pic_id_num_starter, relations = extract_tweet_picture_structure(reply.user, reply, pic_id_num_starter, relations)\n",
    "                        posts[reply_id_name] = post_structure\n",
    "                        \n",
    "                        if picture_structure:\n",
    "                            pictures['pic_' + str(original_pic_id_num)] = picture_structure\n",
    "\n",
    "            \n",
    "        # save the user to the dictionary\n",
    "        user_id_name = 'user_'+ user.id\n",
    "        if user_id_name not in users:\n",
    "            users[user_id_name] = User_Structure\n",
    "\n",
    "\n",
    "        # list that contains all data structures \n",
    "        data_structure_for_twitter = [users, posts, comments, pictures, keywords, relations]\n",
    "        save_json(users, save_path_list[0])\n",
    "        save_json(posts, save_path_list[1])\n",
    "        save_json(pictures, save_path_list[3])\n",
    "        save_json(keywords_dict, save_path_list[4])\n",
    "        save_json(relations, save_path_list[5])\n",
    "        print(account_num)\n",
    "        account_num += 1 \n",
    "    except TooManyRequests as e:\n",
    "        print('Rate limit exceeced')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users)\n",
    "# TODO: Test to see how many unsers to pull, guess 10 time.sleep( about 7.5 - 15 min) in order to not exceed time rates.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
