{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNTelIQvMg5E",
        "outputId": "30b7d138-1c3d-4fcd-87f5-01eafc18272c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U4cBlgihNK_u"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import os\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import AMiner\n",
        "from torch_geometric.nn import MetaPath2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VYdZ25DyEOp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqeIb2d-SYyK",
        "outputId": "2e14373f-131e-4674-bd5a-18cb0dcba3cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://www.dropbox.com/s/1bnz8r7mofx0osf/net_aminer.zip?dl=1\n",
            "Extracting C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\metapath2vec\\Aminer\\net_aminer.zip\n",
            "Downloading https://www.dropbox.com/s/nkocx16rpl4ydde/label.zip?dl=1\n",
            "Extracting C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\metapath2vec\\Aminer\\raw\\label.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "path = r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\metapath2vec\\Aminer'\n",
        "dataset = AMiner(path)\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
            "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
            "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
            "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'y': tensor([0, 2, 5,  ..., 0, 1, 5]), 'y_index': tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374]), 'num_nodes': 1693531}\n"
          ]
        }
      ],
      "source": [
        "print(data['author'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1693531\n",
            "0.11111103821207234\n",
            "Train mask: 24667\n",
            "Validation mask: 24667\n",
            "Test mask: 197344\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Extract the node indices and labels\n",
        "author_labels = data['author']['y']\n",
        "author_indices = data['author']['y_index']\n",
        "num_author_nodes = data['author']['num_nodes']\n",
        "print(num_author_nodes)\n",
        "# print(author_indices)\n",
        "\n",
        "# Calculate the number of nodes for each split\n",
        "num_train = int(0.10 * num_author_nodes)\n",
        "num_train_dec = num_train/num_author_nodes\n",
        "num_val = int(0.10 * num_author_nodes)\n",
        "num_test = num_author_nodes - num_train - num_val\n",
        "\n",
        "\n",
        "# Calculate the number of nodes for each split\n",
        "num_train = int(0.10 * num_author_nodes)\n",
        "num_val = int(0.10 * num_author_nodes)  # Note: we'll use this only for proportional split\n",
        "\n",
        "# First split: Train (10%) and the remaining (90%)\n",
        "train_indices, remaining_indices, train_labels, remaining_labels = train_test_split(\n",
        "    author_indices, author_labels, train_size=num_train_dec, stratify=author_labels, random_state=42)\n",
        "\n",
        "# Proportion of remaining data for validation (10% of total, or 1/9 of remaining)\n",
        "val_proportion = num_val / (num_author_nodes - num_train)\n",
        "print(val_proportion)\n",
        "# Second split: Validation (1/9 of remaining) and Test (8/9 of remaining)\n",
        "val_indices, test_indices, val_labels, test_labels = train_test_split(\n",
        "    remaining_indices, remaining_labels, train_size=val_proportion, stratify=remaining_labels, random_state=42)\n",
        "\n",
        "\n",
        "# Initialize the masks\n",
        "train_mask = torch.zeros(num_author_nodes, dtype=torch.bool)\n",
        "val_mask = torch.zeros(num_author_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_author_nodes, dtype=torch.bool)\n",
        "\n",
        "# Set the appropriate mask values to True\n",
        "train_mask[train_indices] = True\n",
        "val_mask[val_indices] = True\n",
        "test_mask[test_indices] = True\n",
        "\n",
        "# Assign the masks to the data\n",
        "data['author']['train_mask'] = train_mask\n",
        "data['author']['val_mask'] = val_mask\n",
        "data['author']['test_mask'] = test_mask\n",
        "\n",
        "print(\"Train mask:\", train_mask.sum().item())\n",
        "print(\"Validation mask:\", val_mask.sum().item())\n",
        "print(\"Test mask:\", test_mask.sum().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scu4ZZ4MyJsD",
        "outputId": "d8f1b7cd-b84d-412b-8b65-6b8f16513ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall structure of the dataset:\n",
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
            "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
            "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
            "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
            ")\n",
            "\n",
            "Node types and their features:\n",
            "Node type: author\n",
            "  y: tensor([0, 2, 5,  ..., 0, 1, 5])\n",
            "  y_index: tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374])\n",
            "  num_nodes: 1693531\n",
            "Node type: venue\n",
            "  y: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
            "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n",
            "  y_index: tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
            "        2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
            "        1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
            "         492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
            "         721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
            "         477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
            "        3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
            "        1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
            "        2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
            "        2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
            "        1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
            "         208,  462])\n",
            "  num_nodes: 3883\n",
            "Node type: paper\n",
            "  num_nodes: 3194405\n",
            "\n",
            "Edge types and their indices:\n",
            "Edge type: ('paper', 'written_by', 'author')\n",
            "  Edge index shape: torch.Size([2, 9323605])\n",
            "Edge type: ('author', 'writes', 'paper')\n",
            "  Edge index shape: torch.Size([2, 9323605])\n",
            "Edge type: ('paper', 'published_in', 'venue')\n",
            "  Edge index shape: torch.Size([2, 3194405])\n",
            "Edge type: ('venue', 'publishes', 'paper')\n",
            "  Edge index shape: torch.Size([2, 3194405])\n",
            "\n",
            "Example of accessing specific node features:\n",
            "Author features: {'y': tensor([0, 2, 5,  ..., 0, 1, 5]), 'y_index': tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374]), 'num_nodes': 1693531}\n",
            "\n",
            "Example of accessing specific edge indices:\n",
            "Author writes paper edge index: tensor([[      0,       1,       2,  ...,    4393,   21681,  317436],\n",
            "        [      0,       1,       2,  ..., 3194404, 3194404, 3194404]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Print the overall structure of the dataset\n",
        "print(\"Overall structure of the dataset:\")\n",
        "print(data)\n",
        "\n",
        "# List all node types and their features\n",
        "print(\"\\nNode types and their features:\")\n",
        "for node_type in data.node_types:\n",
        "    print(f\"Node type: {node_type}\")\n",
        "    for key, value in data[node_type].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# List all edge types and their indices\n",
        "print(\"\\nEdge types and their indices:\")\n",
        "for edge_type in data.edge_types:\n",
        "    print(f\"Edge type: {edge_type}\")\n",
        "    print(f\"  Edge index shape: {data[edge_type].edge_index.shape}\")\n",
        "\n",
        "# Example of accessing specific node features\n",
        "print(\"\\nExample of accessing specific node features:\")\n",
        "author_features = data['author']\n",
        "print(\"Author features:\", author_features)\n",
        "\n",
        "# Example of accessing specific edge indices\n",
        "print(\"\\nExample of accessing specific edge indices:\")\n",
        "author_paper_edge_index = data['author', 'writes', 'paper'].edge_index\n",
        "print(\"Author writes paper edge index:\", author_paper_edge_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v375kdoANapS",
        "outputId": "cc520c3e-3ce0-4882-bbdf-fbe104f74c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "metapath = [\n",
        "    ('author', 'writes', 'paper'),\n",
        "    ('paper', 'published_in', 'venue'),\n",
        "    ('venue', 'publishes', 'paper'),\n",
        "    ('paper', 'written_by', 'author'),\n",
        "]\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('Cuda')\n",
        "    device = torch.device('cuda')\n",
        "elif torch_geometric.is_xpu_available():\n",
        "    print('xpu')\n",
        "    device = torch.device('xpu')\n",
        "else:\n",
        "    print('cpu')\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
        "                     metapath=metapath, walk_length=50, context_size=7,\n",
        "                     walks_per_node=5, num_negative_samples=5,\n",
        "                     sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=6)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk1NEmrzNR-0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(epoch, log_steps=100, eval_steps=2000):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % log_steps == 0:\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
        "            total_loss = 0\n",
        "\n",
        "        if (i + 1) % eval_steps == 0:\n",
        "            acc = test()\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Acc: {acc:.4f}'))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(train_ratio=0.1):\n",
        "    model.eval()\n",
        "\n",
        "    z = model('author', batch=data['author'].y_index.to(device))\n",
        "    y = data['author'].y\n",
        "\n",
        "    perm = torch.randperm(z.size(0))\n",
        "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
        "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
        "\n",
        "    return model.test(z[train_perm], y[train_perm], z[test_perm], y[test_perm],\n",
        "                      max_iter=150)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTxcOai_NqjO",
        "outputId": "c1b80257-5ba5-4dd0-fe30-54f8ae17cf7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Step: 00100/13231, Loss: 9.1016\n",
            "Epoch: 1, Step: 00200/13231, Loss: 7.5671\n",
            "Epoch: 1, Step: 00300/13231, Loss: 6.4565\n",
            "Epoch: 1, Step: 00400/13231, Loss: 5.8505\n",
            "Epoch: 1, Step: 00500/13231, Loss: 5.5900\n",
            "Epoch: 1, Step: 00600/13231, Loss: 5.4316\n",
            "Epoch: 1, Step: 00700/13231, Loss: 5.2982\n",
            "Epoch: 1, Step: 00800/13231, Loss: 5.1681\n",
            "Epoch: 1, Step: 00900/13231, Loss: 5.0449\n",
            "Epoch: 1, Step: 01000/13231, Loss: 4.9268\n",
            "Epoch: 1, Step: 01100/13231, Loss: 4.8116\n",
            "Epoch: 1, Step: 01200/13231, Loss: 4.7003\n",
            "Epoch: 1, Step: 01300/13231, Loss: 4.5951\n",
            "Epoch: 1, Step: 01400/13231, Loss: 4.4940\n",
            "Epoch: 1, Step: 01500/13231, Loss: 4.3962\n",
            "Epoch: 1, Step: 01600/13231, Loss: 4.2956\n",
            "Epoch: 1, Step: 01700/13231, Loss: 4.2026\n",
            "Epoch: 1, Step: 01800/13231, Loss: 4.1093\n",
            "Epoch: 1, Step: 01900/13231, Loss: 4.0237\n",
            "Epoch: 1, Step: 02000/13231, Loss: 3.9375\n",
            "Epoch: 1, Step: 02000/13231, Acc: 0.2870\n",
            "Epoch: 1, Step: 02100/13231, Loss: 3.8531\n",
            "Epoch: 1, Step: 02200/13231, Loss: 3.7697\n",
            "Epoch: 1, Step: 02300/13231, Loss: 3.6889\n",
            "Epoch: 1, Step: 02400/13231, Loss: 3.6145\n",
            "Epoch: 1, Step: 02500/13231, Loss: 3.5362\n",
            "Epoch: 1, Step: 02600/13231, Loss: 3.4622\n",
            "Epoch: 1, Step: 02700/13231, Loss: 3.3893\n",
            "Epoch: 1, Step: 02800/13231, Loss: 3.3184\n",
            "Epoch: 1, Step: 02900/13231, Loss: 3.2487\n",
            "Epoch: 1, Step: 03000/13231, Loss: 3.1833\n",
            "Epoch: 1, Step: 03100/13231, Loss: 3.1167\n",
            "Epoch: 1, Step: 03200/13231, Loss: 3.0530\n",
            "Epoch: 1, Step: 03300/13231, Loss: 2.9934\n",
            "Epoch: 1, Step: 03400/13231, Loss: 2.9333\n",
            "Epoch: 1, Step: 03500/13231, Loss: 2.8763\n",
            "Epoch: 1, Step: 03600/13231, Loss: 2.8175\n",
            "Epoch: 1, Step: 03700/13231, Loss: 2.7667\n",
            "Epoch: 1, Step: 03800/13231, Loss: 2.7132\n",
            "Epoch: 1, Step: 03900/13231, Loss: 2.6616\n",
            "Epoch: 1, Step: 04000/13231, Loss: 2.6143\n",
            "Epoch: 1, Step: 04000/13231, Acc: 0.4664\n",
            "Epoch: 1, Step: 04100/13231, Loss: 2.5675\n",
            "Epoch: 1, Step: 04200/13231, Loss: 2.5210\n",
            "Epoch: 1, Step: 04300/13231, Loss: 2.4760\n",
            "Epoch: 1, Step: 04400/13231, Loss: 2.4323\n",
            "Epoch: 1, Step: 04500/13231, Loss: 2.3911\n",
            "Epoch: 1, Step: 04600/13231, Loss: 2.3515\n",
            "Epoch: 1, Step: 04700/13231, Loss: 2.3119\n",
            "Epoch: 1, Step: 04800/13231, Loss: 2.2759\n",
            "Epoch: 1, Step: 04900/13231, Loss: 2.2381\n",
            "Epoch: 1, Step: 05000/13231, Loss: 2.2049\n",
            "Epoch: 1, Step: 05100/13231, Loss: 2.1714\n",
            "Epoch: 1, Step: 05200/13231, Loss: 2.1388\n",
            "Epoch: 1, Step: 05300/13231, Loss: 2.1064\n",
            "Epoch: 1, Step: 05400/13231, Loss: 2.0756\n",
            "Epoch: 1, Step: 05500/13231, Loss: 2.0461\n",
            "Epoch: 1, Step: 05600/13231, Loss: 2.0183\n",
            "Epoch: 1, Step: 05700/13231, Loss: 1.9903\n",
            "Epoch: 1, Step: 05800/13231, Loss: 1.9637\n",
            "Epoch: 1, Step: 05900/13231, Loss: 1.9368\n",
            "Epoch: 1, Step: 06000/13231, Loss: 1.9136\n",
            "Epoch: 1, Step: 06000/13231, Acc: 0.6398\n",
            "Epoch: 1, Step: 06100/13231, Loss: 1.8892\n",
            "Epoch: 1, Step: 06200/13231, Loss: 1.8675\n",
            "Epoch: 1, Step: 06300/13231, Loss: 1.8442\n",
            "Epoch: 1, Step: 06400/13231, Loss: 1.8231\n",
            "Epoch: 1, Step: 06500/13231, Loss: 1.8022\n",
            "Epoch: 1, Step: 06600/13231, Loss: 1.7810\n",
            "Epoch: 1, Step: 06700/13231, Loss: 1.7625\n",
            "Epoch: 1, Step: 06800/13231, Loss: 1.7440\n",
            "Epoch: 1, Step: 06900/13231, Loss: 1.7247\n",
            "Epoch: 1, Step: 07000/13231, Loss: 1.7059\n",
            "Epoch: 1, Step: 07100/13231, Loss: 1.6908\n",
            "Epoch: 1, Step: 07200/13231, Loss: 1.6722\n",
            "Epoch: 1, Step: 07300/13231, Loss: 1.6568\n",
            "Epoch: 1, Step: 07400/13231, Loss: 1.6412\n",
            "Epoch: 1, Step: 07500/13231, Loss: 1.6252\n",
            "Epoch: 1, Step: 07600/13231, Loss: 1.6109\n",
            "Epoch: 1, Step: 07700/13231, Loss: 1.5961\n",
            "Epoch: 1, Step: 07800/13231, Loss: 1.5811\n",
            "Epoch: 1, Step: 07900/13231, Loss: 1.5683\n",
            "Epoch: 1, Step: 08000/13231, Loss: 1.5555\n",
            "Epoch: 1, Step: 08000/13231, Acc: 0.7391\n",
            "Epoch: 1, Step: 08100/13231, Loss: 1.5424\n",
            "Epoch: 1, Step: 08200/13231, Loss: 1.5295\n",
            "Epoch: 1, Step: 08300/13231, Loss: 1.5169\n",
            "Epoch: 1, Step: 08400/13231, Loss: 1.5057\n",
            "Epoch: 1, Step: 08500/13231, Loss: 1.4940\n",
            "Epoch: 1, Step: 08600/13231, Loss: 1.4821\n",
            "Epoch: 1, Step: 08700/13231, Loss: 1.4699\n",
            "Epoch: 1, Step: 08800/13231, Loss: 1.4610\n",
            "Epoch: 1, Step: 08900/13231, Loss: 1.4499\n",
            "Epoch: 1, Step: 09000/13231, Loss: 1.4384\n",
            "Epoch: 1, Step: 09100/13231, Loss: 1.4297\n",
            "Epoch: 1, Step: 09200/13231, Loss: 1.4188\n",
            "Epoch: 1, Step: 09300/13231, Loss: 1.4091\n",
            "Epoch: 1, Step: 09400/13231, Loss: 1.4003\n",
            "Epoch: 1, Step: 09500/13231, Loss: 1.3914\n",
            "Epoch: 1, Step: 09600/13231, Loss: 1.3820\n",
            "Epoch: 1, Step: 09700/13231, Loss: 1.3734\n",
            "Epoch: 1, Step: 09800/13231, Loss: 1.3641\n",
            "Epoch: 1, Step: 09900/13231, Loss: 1.3558\n",
            "Epoch: 1, Step: 10000/13231, Loss: 1.3482\n",
            "Epoch: 1, Step: 10000/13231, Acc: 0.7917\n",
            "Epoch: 1, Step: 10100/13231, Loss: 1.3398\n",
            "Epoch: 1, Step: 10200/13231, Loss: 1.3320\n",
            "Epoch: 1, Step: 10300/13231, Loss: 1.3243\n",
            "Epoch: 1, Step: 10400/13231, Loss: 1.3171\n",
            "Epoch: 1, Step: 10500/13231, Loss: 1.3100\n",
            "Epoch: 1, Step: 10600/13231, Loss: 1.3019\n",
            "Epoch: 1, Step: 10700/13231, Loss: 1.2955\n",
            "Epoch: 1, Step: 10800/13231, Loss: 1.2878\n",
            "Epoch: 1, Step: 10900/13231, Loss: 1.2815\n",
            "Epoch: 1, Step: 11000/13231, Loss: 1.2743\n",
            "Epoch: 1, Step: 11100/13231, Loss: 1.2677\n",
            "Epoch: 1, Step: 11200/13231, Loss: 1.2620\n",
            "Epoch: 1, Step: 11300/13231, Loss: 1.2551\n",
            "Epoch: 1, Step: 11400/13231, Loss: 1.2494\n",
            "Epoch: 1, Step: 11500/13231, Loss: 1.2431\n",
            "Epoch: 1, Step: 11600/13231, Loss: 1.2378\n",
            "Epoch: 1, Step: 11700/13231, Loss: 1.2308\n",
            "Epoch: 1, Step: 11800/13231, Loss: 1.2262\n",
            "Epoch: 1, Step: 11900/13231, Loss: 1.2199\n",
            "Epoch: 1, Step: 12000/13231, Loss: 1.2148\n",
            "Epoch: 1, Step: 12000/13231, Acc: 0.8224\n",
            "Epoch: 1, Step: 12100/13231, Loss: 1.2089\n",
            "Epoch: 1, Step: 12200/13231, Loss: 1.2027\n",
            "Epoch: 1, Step: 12300/13231, Loss: 1.1983\n",
            "Epoch: 1, Step: 12400/13231, Loss: 1.1929\n",
            "Epoch: 1, Step: 12500/13231, Loss: 1.1883\n",
            "Epoch: 1, Step: 12600/13231, Loss: 1.1832\n",
            "Epoch: 1, Step: 12700/13231, Loss: 1.1780\n",
            "Epoch: 1, Step: 12800/13231, Loss: 1.1733\n",
            "Epoch: 1, Step: 12900/13231, Loss: 1.1688\n",
            "Epoch: 1, Step: 13000/13231, Loss: 1.1636\n",
            "Epoch: 1, Step: 13100/13231, Loss: 1.1596\n",
            "Epoch: 1, Step: 13200/13231, Loss: 1.1550\n",
            "Epoch: 1, Accuracy: 0.8354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, Step: 00100/13231, Loss: 1.1491\n",
            "Epoch: 2, Step: 00200/13231, Loss: 1.1452\n",
            "Epoch: 2, Step: 00300/13231, Loss: 1.1410\n",
            "Epoch: 2, Step: 00400/13231, Loss: 1.1360\n",
            "Epoch: 2, Step: 00500/13231, Loss: 1.1325\n",
            "Epoch: 2, Step: 00600/13231, Loss: 1.1285\n",
            "Epoch: 2, Step: 00700/13231, Loss: 1.1246\n",
            "Epoch: 2, Step: 00800/13231, Loss: 1.1202\n",
            "Epoch: 2, Step: 00900/13231, Loss: 1.1171\n",
            "Epoch: 2, Step: 01000/13231, Loss: 1.1132\n",
            "Epoch: 2, Step: 01100/13231, Loss: 1.1093\n",
            "Epoch: 2, Step: 01200/13231, Loss: 1.1056\n",
            "Epoch: 2, Step: 01300/13231, Loss: 1.1026\n",
            "Epoch: 2, Step: 01400/13231, Loss: 1.0988\n",
            "Epoch: 2, Step: 01500/13231, Loss: 1.0948\n",
            "Epoch: 2, Step: 01600/13231, Loss: 1.0920\n",
            "Epoch: 2, Step: 01700/13231, Loss: 1.0887\n",
            "Epoch: 2, Step: 01800/13231, Loss: 1.0855\n",
            "Epoch: 2, Step: 01900/13231, Loss: 1.0820\n",
            "Epoch: 2, Step: 02000/13231, Loss: 1.0794\n",
            "Epoch: 2, Step: 02000/13231, Acc: 0.8506\n",
            "Epoch: 2, Step: 02100/13231, Loss: 1.0761\n",
            "Epoch: 2, Step: 02200/13231, Loss: 1.0732\n",
            "Epoch: 2, Step: 02300/13231, Loss: 1.0701\n",
            "Epoch: 2, Step: 02400/13231, Loss: 1.0670\n",
            "Epoch: 2, Step: 02500/13231, Loss: 1.0640\n",
            "Epoch: 2, Step: 02600/13231, Loss: 1.0616\n",
            "Epoch: 2, Step: 02700/13231, Loss: 1.0586\n",
            "Epoch: 2, Step: 02800/13231, Loss: 1.0557\n",
            "Epoch: 2, Step: 02900/13231, Loss: 1.0529\n",
            "Epoch: 2, Step: 03000/13231, Loss: 1.0499\n",
            "Epoch: 2, Step: 03100/13231, Loss: 1.0479\n",
            "Epoch: 2, Step: 03200/13231, Loss: 1.0458\n",
            "Epoch: 2, Step: 03300/13231, Loss: 1.0425\n",
            "Epoch: 2, Step: 03400/13231, Loss: 1.0397\n",
            "Epoch: 2, Step: 03500/13231, Loss: 1.0373\n",
            "Epoch: 2, Step: 03600/13231, Loss: 1.0350\n",
            "Epoch: 2, Step: 03700/13231, Loss: 1.0327\n",
            "Epoch: 2, Step: 03800/13231, Loss: 1.0303\n",
            "Epoch: 2, Step: 03900/13231, Loss: 1.0280\n",
            "Epoch: 2, Step: 04000/13231, Loss: 1.0259\n",
            "Epoch: 2, Step: 04000/13231, Acc: 0.8622\n",
            "Epoch: 2, Step: 04100/13231, Loss: 1.0233\n",
            "Epoch: 2, Step: 04200/13231, Loss: 1.0212\n",
            "Epoch: 2, Step: 04300/13231, Loss: 1.0190\n",
            "Epoch: 2, Step: 04400/13231, Loss: 1.0171\n",
            "Epoch: 2, Step: 04500/13231, Loss: 1.0145\n",
            "Epoch: 2, Step: 04600/13231, Loss: 1.0125\n",
            "Epoch: 2, Step: 04700/13231, Loss: 1.0099\n",
            "Epoch: 2, Step: 04800/13231, Loss: 1.0083\n",
            "Epoch: 2, Step: 04900/13231, Loss: 1.0064\n",
            "Epoch: 2, Step: 05000/13231, Loss: 1.0045\n",
            "Epoch: 2, Step: 05100/13231, Loss: 1.0025\n",
            "Epoch: 2, Step: 05200/13231, Loss: 1.0008\n",
            "Epoch: 2, Step: 05300/13231, Loss: 0.9982\n",
            "Epoch: 2, Step: 05400/13231, Loss: 0.9965\n",
            "Epoch: 2, Step: 05500/13231, Loss: 0.9946\n",
            "Epoch: 2, Step: 05600/13231, Loss: 0.9929\n",
            "Epoch: 2, Step: 05700/13231, Loss: 0.9909\n",
            "Epoch: 2, Step: 05800/13231, Loss: 0.9895\n",
            "Epoch: 2, Step: 05900/13231, Loss: 0.9878\n",
            "Epoch: 2, Step: 06000/13231, Loss: 0.9860\n",
            "Epoch: 2, Step: 06000/13231, Acc: 0.8712\n",
            "Epoch: 2, Step: 06100/13231, Loss: 0.9842\n",
            "Epoch: 2, Step: 06200/13231, Loss: 0.9827\n",
            "Epoch: 2, Step: 06300/13231, Loss: 0.9810\n",
            "Epoch: 2, Step: 06400/13231, Loss: 0.9789\n",
            "Epoch: 2, Step: 06500/13231, Loss: 0.9776\n",
            "Epoch: 2, Step: 06600/13231, Loss: 0.9758\n",
            "Epoch: 2, Step: 06700/13231, Loss: 0.9742\n",
            "Epoch: 2, Step: 06800/13231, Loss: 0.9731\n",
            "Epoch: 2, Step: 06900/13231, Loss: 0.9717\n",
            "Epoch: 2, Step: 07000/13231, Loss: 0.9698\n",
            "Epoch: 2, Step: 07100/13231, Loss: 0.9686\n",
            "Epoch: 2, Step: 07200/13231, Loss: 0.9671\n",
            "Epoch: 2, Step: 07300/13231, Loss: 0.9653\n",
            "Epoch: 2, Step: 07400/13231, Loss: 0.9641\n",
            "Epoch: 2, Step: 07500/13231, Loss: 0.9627\n",
            "Epoch: 2, Step: 07600/13231, Loss: 0.9612\n",
            "Epoch: 2, Step: 07700/13231, Loss: 0.9601\n",
            "Epoch: 2, Step: 07800/13231, Loss: 0.9584\n",
            "Epoch: 2, Step: 07900/13231, Loss: 0.9571\n",
            "Epoch: 2, Step: 08000/13231, Loss: 0.9560\n",
            "Epoch: 2, Step: 08000/13231, Acc: 0.8781\n",
            "Epoch: 2, Step: 08100/13231, Loss: 0.9546\n",
            "Epoch: 2, Step: 08200/13231, Loss: 0.9538\n",
            "Epoch: 2, Step: 08300/13231, Loss: 0.9521\n",
            "Epoch: 2, Step: 08400/13231, Loss: 0.9510\n",
            "Epoch: 2, Step: 08500/13231, Loss: 0.9495\n",
            "Epoch: 2, Step: 08600/13231, Loss: 0.9489\n",
            "Epoch: 2, Step: 08700/13231, Loss: 0.9472\n",
            "Epoch: 2, Step: 08800/13231, Loss: 0.9461\n",
            "Epoch: 2, Step: 08900/13231, Loss: 0.9453\n",
            "Epoch: 2, Step: 09000/13231, Loss: 0.9435\n",
            "Epoch: 2, Step: 09100/13231, Loss: 0.9426\n",
            "Epoch: 2, Step: 09200/13231, Loss: 0.9415\n",
            "Epoch: 2, Step: 09300/13231, Loss: 0.9405\n",
            "Epoch: 2, Step: 09400/13231, Loss: 0.9396\n",
            "Epoch: 2, Step: 09500/13231, Loss: 0.9380\n",
            "Epoch: 2, Step: 09600/13231, Loss: 0.9368\n",
            "Epoch: 2, Step: 09700/13231, Loss: 0.9363\n",
            "Epoch: 2, Step: 09800/13231, Loss: 0.9349\n",
            "Epoch: 2, Step: 09900/13231, Loss: 0.9339\n",
            "Epoch: 2, Step: 10000/13231, Loss: 0.9334\n",
            "Epoch: 2, Step: 10000/13231, Acc: 0.8834\n",
            "Epoch: 2, Step: 10100/13231, Loss: 0.9323\n",
            "Epoch: 2, Step: 10200/13231, Loss: 0.9314\n",
            "Epoch: 2, Step: 10300/13231, Loss: 0.9304\n",
            "Epoch: 2, Step: 10400/13231, Loss: 0.9293\n",
            "Epoch: 2, Step: 10500/13231, Loss: 0.9282\n",
            "Epoch: 2, Step: 10600/13231, Loss: 0.9275\n",
            "Epoch: 2, Step: 10700/13231, Loss: 0.9264\n",
            "Epoch: 2, Step: 10800/13231, Loss: 0.9256\n",
            "Epoch: 2, Step: 10900/13231, Loss: 0.9248\n",
            "Epoch: 2, Step: 11000/13231, Loss: 0.9240\n",
            "Epoch: 2, Step: 11100/13231, Loss: 0.9233\n",
            "Epoch: 2, Step: 11200/13231, Loss: 0.9220\n",
            "Epoch: 2, Step: 11300/13231, Loss: 0.9216\n",
            "Epoch: 2, Step: 11400/13231, Loss: 0.9198\n",
            "Epoch: 2, Step: 11500/13231, Loss: 0.9196\n",
            "Epoch: 2, Step: 11600/13231, Loss: 0.9185\n",
            "Epoch: 2, Step: 11700/13231, Loss: 0.9180\n",
            "Epoch: 2, Step: 11800/13231, Loss: 0.9169\n",
            "Epoch: 2, Step: 11900/13231, Loss: 0.9164\n",
            "Epoch: 2, Step: 12000/13231, Loss: 0.9155\n",
            "Epoch: 2, Step: 12000/13231, Acc: 0.8881\n",
            "Epoch: 2, Step: 12100/13231, Loss: 0.9146\n",
            "Epoch: 2, Step: 12200/13231, Loss: 0.9141\n",
            "Epoch: 2, Step: 12300/13231, Loss: 0.9133\n",
            "Epoch: 2, Step: 12400/13231, Loss: 0.9123\n",
            "Epoch: 2, Step: 12500/13231, Loss: 0.9117\n",
            "Epoch: 2, Step: 12600/13231, Loss: 0.9109\n",
            "Epoch: 2, Step: 12700/13231, Loss: 0.9100\n",
            "Epoch: 2, Step: 12800/13231, Loss: 0.9097\n",
            "Epoch: 2, Step: 12900/13231, Loss: 0.9090\n",
            "Epoch: 2, Step: 13000/13231, Loss: 0.9084\n",
            "Epoch: 2, Step: 13100/13231, Loss: 0.9076\n",
            "Epoch: 2, Step: 13200/13231, Loss: 0.9070\n",
            "Epoch: 2, Accuracy: 0.8908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3, Step: 00100/13231, Loss: 0.9057\n",
            "Epoch: 3, Step: 00200/13231, Loss: 0.9049\n",
            "Epoch: 3, Step: 00300/13231, Loss: 0.9039\n",
            "Epoch: 3, Step: 00400/13231, Loss: 0.9036\n",
            "Epoch: 3, Step: 00500/13231, Loss: 0.9032\n",
            "Epoch: 3, Step: 00600/13231, Loss: 0.9026\n",
            "Epoch: 3, Step: 00700/13231, Loss: 0.9019\n",
            "Epoch: 3, Step: 00800/13231, Loss: 0.9010\n",
            "Epoch: 3, Step: 00900/13231, Loss: 0.9008\n",
            "Epoch: 3, Step: 01000/13231, Loss: 0.8997\n",
            "Epoch: 3, Step: 01100/13231, Loss: 0.8995\n",
            "Epoch: 3, Step: 01200/13231, Loss: 0.8991\n",
            "Epoch: 3, Step: 01300/13231, Loss: 0.8982\n",
            "Epoch: 3, Step: 01400/13231, Loss: 0.8973\n",
            "Epoch: 3, Step: 01500/13231, Loss: 0.8969\n",
            "Epoch: 3, Step: 01600/13231, Loss: 0.8965\n",
            "Epoch: 3, Step: 01700/13231, Loss: 0.8961\n",
            "Epoch: 3, Step: 01800/13231, Loss: 0.8951\n",
            "Epoch: 3, Step: 01900/13231, Loss: 0.8947\n",
            "Epoch: 3, Step: 02000/13231, Loss: 0.8945\n",
            "Epoch: 3, Step: 02000/13231, Acc: 0.8929\n",
            "Epoch: 3, Step: 02100/13231, Loss: 0.8938\n",
            "Epoch: 3, Step: 02200/13231, Loss: 0.8934\n",
            "Epoch: 3, Step: 02300/13231, Loss: 0.8930\n",
            "Epoch: 3, Step: 02400/13231, Loss: 0.8923\n",
            "Epoch: 3, Step: 02500/13231, Loss: 0.8916\n",
            "Epoch: 3, Step: 02600/13231, Loss: 0.8911\n",
            "Epoch: 3, Step: 02700/13231, Loss: 0.8907\n",
            "Epoch: 3, Step: 02800/13231, Loss: 0.8903\n",
            "Epoch: 3, Step: 02900/13231, Loss: 0.8899\n",
            "Epoch: 3, Step: 03000/13231, Loss: 0.8891\n",
            "Epoch: 3, Step: 03100/13231, Loss: 0.8886\n",
            "Epoch: 3, Step: 03200/13231, Loss: 0.8886\n",
            "Epoch: 3, Step: 03300/13231, Loss: 0.8879\n",
            "Epoch: 3, Step: 03400/13231, Loss: 0.8872\n",
            "Epoch: 3, Step: 03500/13231, Loss: 0.8870\n",
            "Epoch: 3, Step: 03600/13231, Loss: 0.8868\n",
            "Epoch: 3, Step: 03700/13231, Loss: 0.8863\n",
            "Epoch: 3, Step: 03800/13231, Loss: 0.8857\n",
            "Epoch: 3, Step: 03900/13231, Loss: 0.8851\n",
            "Epoch: 3, Step: 04000/13231, Loss: 0.8847\n",
            "Epoch: 3, Step: 04000/13231, Acc: 0.8959\n",
            "Epoch: 3, Step: 04100/13231, Loss: 0.8845\n",
            "Epoch: 3, Step: 04200/13231, Loss: 0.8841\n",
            "Epoch: 3, Step: 04300/13231, Loss: 0.8838\n",
            "Epoch: 3, Step: 04400/13231, Loss: 0.8832\n",
            "Epoch: 3, Step: 04500/13231, Loss: 0.8823\n",
            "Epoch: 3, Step: 04600/13231, Loss: 0.8823\n",
            "Epoch: 3, Step: 04700/13231, Loss: 0.8817\n",
            "Epoch: 3, Step: 04800/13231, Loss: 0.8815\n",
            "Epoch: 3, Step: 04900/13231, Loss: 0.8810\n",
            "Epoch: 3, Step: 05000/13231, Loss: 0.8807\n",
            "Epoch: 3, Step: 05100/13231, Loss: 0.8801\n",
            "Epoch: 3, Step: 05200/13231, Loss: 0.8799\n",
            "Epoch: 3, Step: 05300/13231, Loss: 0.8793\n",
            "Epoch: 3, Step: 05400/13231, Loss: 0.8793\n",
            "Epoch: 3, Step: 05500/13231, Loss: 0.8788\n",
            "Epoch: 3, Step: 05600/13231, Loss: 0.8785\n",
            "Epoch: 3, Step: 05700/13231, Loss: 0.8777\n",
            "Epoch: 3, Step: 05800/13231, Loss: 0.8775\n",
            "Epoch: 3, Step: 05900/13231, Loss: 0.8774\n",
            "Epoch: 3, Step: 06000/13231, Loss: 0.8770\n",
            "Epoch: 3, Step: 06000/13231, Acc: 0.8991\n",
            "Epoch: 3, Step: 06100/13231, Loss: 0.8769\n",
            "Epoch: 3, Step: 06200/13231, Loss: 0.8763\n",
            "Epoch: 3, Step: 06300/13231, Loss: 0.8756\n",
            "Epoch: 3, Step: 06400/13231, Loss: 0.8757\n",
            "Epoch: 3, Step: 06500/13231, Loss: 0.8752\n",
            "Epoch: 3, Step: 06600/13231, Loss: 0.8748\n",
            "Epoch: 3, Step: 06700/13231, Loss: 0.8746\n",
            "Epoch: 3, Step: 06800/13231, Loss: 0.8744\n",
            "Epoch: 3, Step: 06900/13231, Loss: 0.8739\n",
            "Epoch: 3, Step: 07000/13231, Loss: 0.8734\n",
            "Epoch: 3, Step: 07100/13231, Loss: 0.8729\n",
            "Epoch: 3, Step: 07200/13231, Loss: 0.8726\n",
            "Epoch: 3, Step: 07300/13231, Loss: 0.8725\n",
            "Epoch: 3, Step: 07400/13231, Loss: 0.8725\n",
            "Epoch: 3, Step: 07500/13231, Loss: 0.8716\n",
            "Epoch: 3, Step: 07600/13231, Loss: 0.8717\n",
            "Epoch: 3, Step: 07700/13231, Loss: 0.8714\n",
            "Epoch: 3, Step: 07800/13231, Loss: 0.8713\n",
            "Epoch: 3, Step: 07900/13231, Loss: 0.8707\n",
            "Epoch: 3, Step: 08000/13231, Loss: 0.8704\n",
            "Epoch: 3, Step: 08000/13231, Acc: 0.9006\n",
            "Epoch: 3, Step: 08100/13231, Loss: 0.8702\n",
            "Epoch: 3, Step: 08200/13231, Loss: 0.8699\n",
            "Epoch: 3, Step: 08300/13231, Loss: 0.8697\n",
            "Epoch: 3, Step: 08400/13231, Loss: 0.8693\n",
            "Epoch: 3, Step: 08500/13231, Loss: 0.8693\n",
            "Epoch: 3, Step: 08600/13231, Loss: 0.8688\n",
            "Epoch: 3, Step: 08700/13231, Loss: 0.8683\n",
            "Epoch: 3, Step: 08800/13231, Loss: 0.8680\n",
            "Epoch: 3, Step: 08900/13231, Loss: 0.8683\n",
            "Epoch: 3, Step: 09000/13231, Loss: 0.8677\n",
            "Epoch: 3, Step: 09100/13231, Loss: 0.8675\n",
            "Epoch: 3, Step: 09200/13231, Loss: 0.8667\n",
            "Epoch: 3, Step: 09300/13231, Loss: 0.8669\n",
            "Epoch: 3, Step: 09400/13231, Loss: 0.8669\n",
            "Epoch: 3, Step: 09500/13231, Loss: 0.8663\n",
            "Epoch: 3, Step: 09600/13231, Loss: 0.8660\n",
            "Epoch: 3, Step: 09700/13231, Loss: 0.8657\n",
            "Epoch: 3, Step: 09800/13231, Loss: 0.8653\n",
            "Epoch: 3, Step: 09900/13231, Loss: 0.8654\n",
            "Epoch: 3, Step: 10000/13231, Loss: 0.8652\n",
            "Epoch: 3, Step: 10000/13231, Acc: 0.9014\n",
            "Epoch: 3, Step: 10100/13231, Loss: 0.8647\n",
            "Epoch: 3, Step: 10200/13231, Loss: 0.8647\n",
            "Epoch: 3, Step: 10300/13231, Loss: 0.8646\n",
            "Epoch: 3, Step: 10400/13231, Loss: 0.8642\n",
            "Epoch: 3, Step: 10500/13231, Loss: 0.8639\n",
            "Epoch: 3, Step: 10600/13231, Loss: 0.8638\n",
            "Epoch: 3, Step: 10700/13231, Loss: 0.8636\n",
            "Epoch: 3, Step: 10800/13231, Loss: 0.8630\n",
            "Epoch: 3, Step: 10900/13231, Loss: 0.8624\n",
            "Epoch: 3, Step: 11000/13231, Loss: 0.8628\n",
            "Epoch: 3, Step: 11100/13231, Loss: 0.8622\n",
            "Epoch: 3, Step: 11200/13231, Loss: 0.8624\n",
            "Epoch: 3, Step: 11300/13231, Loss: 0.8620\n",
            "Epoch: 3, Step: 11400/13231, Loss: 0.8616\n",
            "Epoch: 3, Step: 11500/13231, Loss: 0.8614\n",
            "Epoch: 3, Step: 11600/13231, Loss: 0.8613\n",
            "Epoch: 3, Step: 11700/13231, Loss: 0.8612\n",
            "Epoch: 3, Step: 11800/13231, Loss: 0.8607\n",
            "Epoch: 3, Step: 11900/13231, Loss: 0.8610\n",
            "Epoch: 3, Step: 12000/13231, Loss: 0.8603\n",
            "Epoch: 3, Step: 12000/13231, Acc: 0.9042\n",
            "Epoch: 3, Step: 12100/13231, Loss: 0.8606\n",
            "Epoch: 3, Step: 12200/13231, Loss: 0.8602\n",
            "Epoch: 3, Step: 12300/13231, Loss: 0.8597\n",
            "Epoch: 3, Step: 12400/13231, Loss: 0.8598\n",
            "Epoch: 3, Step: 12500/13231, Loss: 0.8597\n",
            "Epoch: 3, Step: 12600/13231, Loss: 0.8599\n",
            "Epoch: 3, Step: 12700/13231, Loss: 0.8590\n",
            "Epoch: 3, Step: 12800/13231, Loss: 0.8590\n",
            "Epoch: 3, Step: 12900/13231, Loss: 0.8590\n",
            "Epoch: 3, Step: 13000/13231, Loss: 0.8586\n",
            "Epoch: 3, Step: 13100/13231, Loss: 0.8582\n",
            "Epoch: 3, Step: 13200/13231, Loss: 0.8584\n",
            "Epoch: 3, Accuracy: 0.9053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4, Step: 00100/13231, Loss: 0.8581\n",
            "Epoch: 4, Step: 00200/13231, Loss: 0.8577\n",
            "Epoch: 4, Step: 00300/13231, Loss: 0.8571\n",
            "Epoch: 4, Step: 00400/13231, Loss: 0.8573\n",
            "Epoch: 4, Step: 00500/13231, Loss: 0.8569\n",
            "Epoch: 4, Step: 00600/13231, Loss: 0.8568\n",
            "Epoch: 4, Step: 00700/13231, Loss: 0.8564\n",
            "Epoch: 4, Step: 00800/13231, Loss: 0.8566\n",
            "Epoch: 4, Step: 00900/13231, Loss: 0.8564\n",
            "Epoch: 4, Step: 01000/13231, Loss: 0.8560\n",
            "Epoch: 4, Step: 01100/13231, Loss: 0.8555\n",
            "Epoch: 4, Step: 01200/13231, Loss: 0.8559\n",
            "Epoch: 4, Step: 01300/13231, Loss: 0.8553\n",
            "Epoch: 4, Step: 01400/13231, Loss: 0.8551\n",
            "Epoch: 4, Step: 01500/13231, Loss: 0.8551\n",
            "Epoch: 4, Step: 01600/13231, Loss: 0.8546\n",
            "Epoch: 4, Step: 01700/13231, Loss: 0.8548\n",
            "Epoch: 4, Step: 01800/13231, Loss: 0.8545\n",
            "Epoch: 4, Step: 01900/13231, Loss: 0.8544\n",
            "Epoch: 4, Step: 02000/13231, Loss: 0.8543\n",
            "Epoch: 4, Step: 02000/13231, Acc: 0.9063\n",
            "Epoch: 4, Step: 02100/13231, Loss: 0.8540\n",
            "Epoch: 4, Step: 02200/13231, Loss: 0.8540\n",
            "Epoch: 4, Step: 02300/13231, Loss: 0.8538\n",
            "Epoch: 4, Step: 02400/13231, Loss: 0.8536\n",
            "Epoch: 4, Step: 02500/13231, Loss: 0.8535\n",
            "Epoch: 4, Step: 02600/13231, Loss: 0.8532\n",
            "Epoch: 4, Step: 02700/13231, Loss: 0.8532\n",
            "Epoch: 4, Step: 02800/13231, Loss: 0.8532\n",
            "Epoch: 4, Step: 02900/13231, Loss: 0.8527\n",
            "Epoch: 4, Step: 03000/13231, Loss: 0.8529\n",
            "Epoch: 4, Step: 03100/13231, Loss: 0.8528\n",
            "Epoch: 4, Step: 03200/13231, Loss: 0.8527\n",
            "Epoch: 4, Step: 03300/13231, Loss: 0.8524\n",
            "Epoch: 4, Step: 03400/13231, Loss: 0.8521\n",
            "Epoch: 4, Step: 03500/13231, Loss: 0.8521\n",
            "Epoch: 4, Step: 03600/13231, Loss: 0.8519\n",
            "Epoch: 4, Step: 03700/13231, Loss: 0.8521\n",
            "Epoch: 4, Step: 03800/13231, Loss: 0.8514\n",
            "Epoch: 4, Step: 03900/13231, Loss: 0.8515\n",
            "Epoch: 4, Step: 04000/13231, Loss: 0.8514\n",
            "Epoch: 4, Step: 04000/13231, Acc: 0.9085\n",
            "Epoch: 4, Step: 04100/13231, Loss: 0.8514\n",
            "Epoch: 4, Step: 04200/13231, Loss: 0.8513\n",
            "Epoch: 4, Step: 04300/13231, Loss: 0.8510\n",
            "Epoch: 4, Step: 04400/13231, Loss: 0.8509\n",
            "Epoch: 4, Step: 04500/13231, Loss: 0.8508\n",
            "Epoch: 4, Step: 04600/13231, Loss: 0.8506\n",
            "Epoch: 4, Step: 04700/13231, Loss: 0.8504\n",
            "Epoch: 4, Step: 04800/13231, Loss: 0.8503\n",
            "Epoch: 4, Step: 04900/13231, Loss: 0.8504\n",
            "Epoch: 4, Step: 05000/13231, Loss: 0.8501\n",
            "Epoch: 4, Step: 05100/13231, Loss: 0.8500\n",
            "Epoch: 4, Step: 05200/13231, Loss: 0.8496\n",
            "Epoch: 4, Step: 05300/13231, Loss: 0.8496\n",
            "Epoch: 4, Step: 05400/13231, Loss: 0.8497\n",
            "Epoch: 4, Step: 05500/13231, Loss: 0.8495\n",
            "Epoch: 4, Step: 05600/13231, Loss: 0.8498\n",
            "Epoch: 4, Step: 05700/13231, Loss: 0.8494\n",
            "Epoch: 4, Step: 05800/13231, Loss: 0.8490\n",
            "Epoch: 4, Step: 05900/13231, Loss: 0.8489\n",
            "Epoch: 4, Step: 06000/13231, Loss: 0.8488\n",
            "Epoch: 4, Step: 06000/13231, Acc: 0.9100\n",
            "Epoch: 4, Step: 06100/13231, Loss: 0.8490\n",
            "Epoch: 4, Step: 06200/13231, Loss: 0.8483\n",
            "Epoch: 4, Step: 06300/13231, Loss: 0.8485\n",
            "Epoch: 4, Step: 06400/13231, Loss: 0.8484\n",
            "Epoch: 4, Step: 06500/13231, Loss: 0.8483\n",
            "Epoch: 4, Step: 06600/13231, Loss: 0.8480\n",
            "Epoch: 4, Step: 06700/13231, Loss: 0.8480\n",
            "Epoch: 4, Step: 06800/13231, Loss: 0.8481\n",
            "Epoch: 4, Step: 06900/13231, Loss: 0.8477\n",
            "Epoch: 4, Step: 07000/13231, Loss: 0.8476\n",
            "Epoch: 4, Step: 07100/13231, Loss: 0.8480\n",
            "Epoch: 4, Step: 07200/13231, Loss: 0.8471\n",
            "Epoch: 4, Step: 07300/13231, Loss: 0.8472\n",
            "Epoch: 4, Step: 07400/13231, Loss: 0.8472\n",
            "Epoch: 4, Step: 07500/13231, Loss: 0.8472\n",
            "Epoch: 4, Step: 07600/13231, Loss: 0.8467\n",
            "Epoch: 4, Step: 07700/13231, Loss: 0.8468\n",
            "Epoch: 4, Step: 07800/13231, Loss: 0.8466\n",
            "Epoch: 4, Step: 07900/13231, Loss: 0.8463\n",
            "Epoch: 4, Step: 08000/13231, Loss: 0.8465\n",
            "Epoch: 4, Step: 08000/13231, Acc: 0.9108\n",
            "Epoch: 4, Step: 08100/13231, Loss: 0.8464\n",
            "Epoch: 4, Step: 08200/13231, Loss: 0.8462\n",
            "Epoch: 4, Step: 08300/13231, Loss: 0.8463\n",
            "Epoch: 4, Step: 08400/13231, Loss: 0.8460\n",
            "Epoch: 4, Step: 08500/13231, Loss: 0.8462\n",
            "Epoch: 4, Step: 08600/13231, Loss: 0.8463\n",
            "Epoch: 4, Step: 08700/13231, Loss: 0.8458\n",
            "Epoch: 4, Step: 08800/13231, Loss: 0.8460\n",
            "Epoch: 4, Step: 08900/13231, Loss: 0.8455\n",
            "Epoch: 4, Step: 09000/13231, Loss: 0.8456\n",
            "Epoch: 4, Step: 09100/13231, Loss: 0.8454\n",
            "Epoch: 4, Step: 09200/13231, Loss: 0.8455\n",
            "Epoch: 4, Step: 09300/13231, Loss: 0.8454\n",
            "Epoch: 4, Step: 09400/13231, Loss: 0.8450\n",
            "Epoch: 4, Step: 09500/13231, Loss: 0.8452\n",
            "Epoch: 4, Step: 09600/13231, Loss: 0.8447\n",
            "Epoch: 4, Step: 09700/13231, Loss: 0.8450\n",
            "Epoch: 4, Step: 09800/13231, Loss: 0.8448\n",
            "Epoch: 4, Step: 09900/13231, Loss: 0.8449\n",
            "Epoch: 4, Step: 10000/13231, Loss: 0.8445\n",
            "Epoch: 4, Step: 10000/13231, Acc: 0.9120\n",
            "Epoch: 4, Step: 10100/13231, Loss: 0.8444\n",
            "Epoch: 4, Step: 10200/13231, Loss: 0.8441\n",
            "Epoch: 4, Step: 10300/13231, Loss: 0.8439\n",
            "Epoch: 4, Step: 10400/13231, Loss: 0.8444\n",
            "Epoch: 4, Step: 10500/13231, Loss: 0.8441\n",
            "Epoch: 4, Step: 10600/13231, Loss: 0.8439\n",
            "Epoch: 4, Step: 10700/13231, Loss: 0.8440\n",
            "Epoch: 4, Step: 10800/13231, Loss: 0.8436\n",
            "Epoch: 4, Step: 10900/13231, Loss: 0.8436\n",
            "Epoch: 4, Step: 11000/13231, Loss: 0.8436\n",
            "Epoch: 4, Step: 11100/13231, Loss: 0.8434\n",
            "Epoch: 4, Step: 11200/13231, Loss: 0.8436\n",
            "Epoch: 4, Step: 11300/13231, Loss: 0.8432\n",
            "Epoch: 4, Step: 11400/13231, Loss: 0.8435\n",
            "Epoch: 4, Step: 11500/13231, Loss: 0.8431\n",
            "Epoch: 4, Step: 11600/13231, Loss: 0.8426\n",
            "Epoch: 4, Step: 11700/13231, Loss: 0.8431\n",
            "Epoch: 4, Step: 11800/13231, Loss: 0.8433\n",
            "Epoch: 4, Step: 11900/13231, Loss: 0.8429\n",
            "Epoch: 4, Step: 12000/13231, Loss: 0.8429\n",
            "Epoch: 4, Step: 12000/13231, Acc: 0.9120\n",
            "Epoch: 4, Step: 12100/13231, Loss: 0.8422\n",
            "Epoch: 4, Step: 12200/13231, Loss: 0.8426\n",
            "Epoch: 4, Step: 12300/13231, Loss: 0.8427\n",
            "Epoch: 4, Step: 12400/13231, Loss: 0.8424\n",
            "Epoch: 4, Step: 12500/13231, Loss: 0.8424\n",
            "Epoch: 4, Step: 12600/13231, Loss: 0.8421\n",
            "Epoch: 4, Step: 12700/13231, Loss: 0.8426\n",
            "Epoch: 4, Step: 12800/13231, Loss: 0.8424\n",
            "Epoch: 4, Step: 12900/13231, Loss: 0.8419\n",
            "Epoch: 4, Step: 13000/13231, Loss: 0.8419\n",
            "Epoch: 4, Step: 13100/13231, Loss: 0.8418\n",
            "Epoch: 4, Step: 13200/13231, Loss: 0.8418\n",
            "Epoch: 4, Accuracy: 0.9134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5, Step: 00100/13231, Loss: 0.8417\n",
            "Epoch: 5, Step: 00200/13231, Loss: 0.8414\n",
            "Epoch: 5, Step: 00300/13231, Loss: 0.8414\n",
            "Epoch: 5, Step: 00400/13231, Loss: 0.8412\n",
            "Epoch: 5, Step: 00500/13231, Loss: 0.8411\n",
            "Epoch: 5, Step: 00600/13231, Loss: 0.8415\n",
            "Epoch: 5, Step: 00700/13231, Loss: 0.8410\n",
            "Epoch: 5, Step: 00800/13231, Loss: 0.8410\n",
            "Epoch: 5, Step: 00900/13231, Loss: 0.8409\n",
            "Epoch: 5, Step: 01000/13231, Loss: 0.8409\n",
            "Epoch: 5, Step: 01100/13231, Loss: 0.8408\n",
            "Epoch: 5, Step: 01200/13231, Loss: 0.8407\n",
            "Epoch: 5, Step: 01300/13231, Loss: 0.8407\n",
            "Epoch: 5, Step: 01400/13231, Loss: 0.8404\n",
            "Epoch: 5, Step: 01500/13231, Loss: 0.8405\n",
            "Epoch: 5, Step: 01600/13231, Loss: 0.8402\n",
            "Epoch: 5, Step: 01700/13231, Loss: 0.8403\n",
            "Epoch: 5, Step: 01800/13231, Loss: 0.8404\n",
            "Epoch: 5, Step: 01900/13231, Loss: 0.8403\n",
            "Epoch: 5, Step: 02000/13231, Loss: 0.8405\n",
            "Epoch: 5, Step: 02000/13231, Acc: 0.9144\n",
            "Epoch: 5, Step: 02100/13231, Loss: 0.8401\n",
            "Epoch: 5, Step: 02200/13231, Loss: 0.8399\n",
            "Epoch: 5, Step: 02300/13231, Loss: 0.8398\n",
            "Epoch: 5, Step: 02400/13231, Loss: 0.8394\n",
            "Epoch: 5, Step: 02500/13231, Loss: 0.8397\n",
            "Epoch: 5, Step: 02600/13231, Loss: 0.8398\n",
            "Epoch: 5, Step: 02700/13231, Loss: 0.8398\n",
            "Epoch: 5, Step: 02800/13231, Loss: 0.8399\n",
            "Epoch: 5, Step: 02900/13231, Loss: 0.8398\n",
            "Epoch: 5, Step: 03000/13231, Loss: 0.8396\n",
            "Epoch: 5, Step: 03100/13231, Loss: 0.8396\n",
            "Epoch: 5, Step: 03200/13231, Loss: 0.8396\n",
            "Epoch: 5, Step: 03300/13231, Loss: 0.8396\n",
            "Epoch: 5, Step: 03400/13231, Loss: 0.8392\n",
            "Epoch: 5, Step: 03500/13231, Loss: 0.8393\n",
            "Epoch: 5, Step: 03600/13231, Loss: 0.8391\n",
            "Epoch: 5, Step: 03700/13231, Loss: 0.8393\n",
            "Epoch: 5, Step: 03800/13231, Loss: 0.8390\n",
            "Epoch: 5, Step: 03900/13231, Loss: 0.8392\n",
            "Epoch: 5, Step: 04000/13231, Loss: 0.8392\n",
            "Epoch: 5, Step: 04000/13231, Acc: 0.9147\n",
            "Epoch: 5, Step: 04100/13231, Loss: 0.8387\n",
            "Epoch: 5, Step: 04200/13231, Loss: 0.8388\n",
            "Epoch: 5, Step: 04300/13231, Loss: 0.8388\n",
            "Epoch: 5, Step: 04400/13231, Loss: 0.8391\n",
            "Epoch: 5, Step: 04500/13231, Loss: 0.8387\n",
            "Epoch: 5, Step: 04600/13231, Loss: 0.8390\n",
            "Epoch: 5, Step: 04700/13231, Loss: 0.8384\n",
            "Epoch: 5, Step: 04800/13231, Loss: 0.8386\n",
            "Epoch: 5, Step: 04900/13231, Loss: 0.8383\n",
            "Epoch: 5, Step: 05000/13231, Loss: 0.8388\n",
            "Epoch: 5, Step: 05100/13231, Loss: 0.8383\n",
            "Epoch: 5, Step: 05200/13231, Loss: 0.8386\n",
            "Epoch: 5, Step: 05300/13231, Loss: 0.8382\n",
            "Epoch: 5, Step: 05400/13231, Loss: 0.8383\n",
            "Epoch: 5, Step: 05500/13231, Loss: 0.8383\n",
            "Epoch: 5, Step: 05600/13231, Loss: 0.8382\n",
            "Epoch: 5, Step: 05700/13231, Loss: 0.8380\n",
            "Epoch: 5, Step: 05800/13231, Loss: 0.8382\n",
            "Epoch: 5, Step: 05900/13231, Loss: 0.8382\n",
            "Epoch: 5, Step: 06000/13231, Loss: 0.8380\n",
            "Epoch: 5, Step: 06000/13231, Acc: 0.9160\n",
            "Epoch: 5, Step: 06100/13231, Loss: 0.8377\n",
            "Epoch: 5, Step: 06200/13231, Loss: 0.8381\n",
            "Epoch: 5, Step: 06300/13231, Loss: 0.8377\n",
            "Epoch: 5, Step: 06400/13231, Loss: 0.8376\n",
            "Epoch: 5, Step: 06500/13231, Loss: 0.8374\n",
            "Epoch: 5, Step: 06600/13231, Loss: 0.8377\n",
            "Epoch: 5, Step: 06700/13231, Loss: 0.8373\n",
            "Epoch: 5, Step: 06800/13231, Loss: 0.8373\n",
            "Epoch: 5, Step: 06900/13231, Loss: 0.8374\n",
            "Epoch: 5, Step: 07000/13231, Loss: 0.8371\n",
            "Epoch: 5, Step: 07100/13231, Loss: 0.8374\n",
            "Epoch: 5, Step: 07200/13231, Loss: 0.8375\n",
            "Epoch: 5, Step: 07300/13231, Loss: 0.8371\n",
            "Epoch: 5, Step: 07400/13231, Loss: 0.8372\n",
            "Epoch: 5, Step: 07500/13231, Loss: 0.8371\n",
            "Epoch: 5, Step: 07600/13231, Loss: 0.8370\n",
            "Epoch: 5, Step: 07700/13231, Loss: 0.8370\n",
            "Epoch: 5, Step: 07800/13231, Loss: 0.8370\n",
            "Epoch: 5, Step: 07900/13231, Loss: 0.8372\n",
            "Epoch: 5, Step: 08000/13231, Loss: 0.8369\n",
            "Epoch: 5, Step: 08000/13231, Acc: 0.9162\n",
            "Epoch: 5, Step: 08100/13231, Loss: 0.8368\n",
            "Epoch: 5, Step: 08200/13231, Loss: 0.8369\n",
            "Epoch: 5, Step: 08300/13231, Loss: 0.8370\n",
            "Epoch: 5, Step: 08400/13231, Loss: 0.8367\n",
            "Epoch: 5, Step: 08500/13231, Loss: 0.8367\n",
            "Epoch: 5, Step: 08600/13231, Loss: 0.8367\n",
            "Epoch: 5, Step: 08700/13231, Loss: 0.8365\n",
            "Epoch: 5, Step: 08800/13231, Loss: 0.8364\n",
            "Epoch: 5, Step: 08900/13231, Loss: 0.8366\n",
            "Epoch: 5, Step: 09000/13231, Loss: 0.8364\n",
            "Epoch: 5, Step: 09100/13231, Loss: 0.8366\n",
            "Epoch: 5, Step: 09200/13231, Loss: 0.8366\n",
            "Epoch: 5, Step: 09300/13231, Loss: 0.8366\n",
            "Epoch: 5, Step: 09400/13231, Loss: 0.8364\n",
            "Epoch: 5, Step: 09500/13231, Loss: 0.8366\n",
            "Epoch: 5, Step: 09600/13231, Loss: 0.8362\n",
            "Epoch: 5, Step: 09700/13231, Loss: 0.8358\n",
            "Epoch: 5, Step: 09800/13231, Loss: 0.8363\n",
            "Epoch: 5, Step: 09900/13231, Loss: 0.8363\n",
            "Epoch: 5, Step: 10000/13231, Loss: 0.8359\n",
            "Epoch: 5, Step: 10000/13231, Acc: 0.9170\n",
            "Epoch: 5, Step: 10100/13231, Loss: 0.8359\n",
            "Epoch: 5, Step: 10200/13231, Loss: 0.8363\n",
            "Epoch: 5, Step: 10300/13231, Loss: 0.8359\n",
            "Epoch: 5, Step: 10400/13231, Loss: 0.8359\n",
            "Epoch: 5, Step: 10500/13231, Loss: 0.8358\n",
            "Epoch: 5, Step: 10600/13231, Loss: 0.8357\n",
            "Epoch: 5, Step: 10700/13231, Loss: 0.8359\n",
            "Epoch: 5, Step: 10800/13231, Loss: 0.8358\n",
            "Epoch: 5, Step: 10900/13231, Loss: 0.8358\n",
            "Epoch: 5, Step: 11000/13231, Loss: 0.8357\n",
            "Epoch: 5, Step: 11100/13231, Loss: 0.8357\n",
            "Epoch: 5, Step: 11200/13231, Loss: 0.8356\n",
            "Epoch: 5, Step: 11300/13231, Loss: 0.8356\n",
            "Epoch: 5, Step: 11400/13231, Loss: 0.8355\n",
            "Epoch: 5, Step: 11500/13231, Loss: 0.8355\n",
            "Epoch: 5, Step: 11600/13231, Loss: 0.8355\n",
            "Epoch: 5, Step: 11700/13231, Loss: 0.8351\n",
            "Epoch: 5, Step: 11800/13231, Loss: 0.8354\n",
            "Epoch: 5, Step: 11900/13231, Loss: 0.8353\n",
            "Epoch: 5, Step: 12000/13231, Loss: 0.8351\n",
            "Epoch: 5, Step: 12000/13231, Acc: 0.9184\n",
            "Epoch: 5, Step: 12100/13231, Loss: 0.8352\n",
            "Epoch: 5, Step: 12200/13231, Loss: 0.8353\n",
            "Epoch: 5, Step: 12300/13231, Loss: 0.8355\n",
            "Epoch: 5, Step: 12400/13231, Loss: 0.8355\n",
            "Epoch: 5, Step: 12500/13231, Loss: 0.8352\n",
            "Epoch: 5, Step: 12600/13231, Loss: 0.8353\n",
            "Epoch: 5, Step: 12700/13231, Loss: 0.8351\n",
            "Epoch: 5, Step: 12800/13231, Loss: 0.8350\n",
            "Epoch: 5, Step: 12900/13231, Loss: 0.8353\n",
            "Epoch: 5, Step: 13000/13231, Loss: 0.8352\n",
            "Epoch: 5, Step: 13100/13231, Loss: 0.8352\n",
            "Epoch: 5, Step: 13200/13231, Loss: 0.8350\n",
            "Epoch: 5, Accuracy: 0.9173\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(1, 6):\n",
        "    train(epoch)\n",
        "    acc = test()\n",
        "    print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2QH9HDnXFcb"
      },
      "outputs": [],
      "source": [
        "10% training,10%validation, 80% test, splitting the training mask and split evenly by the label\n",
        "DBLP hetero\n",
        "LastFM\n",
        "author node; venue nodes; paper nodes\n",
        "\n",
        "run DBLP and LastFM the same splits\n",
        "\n",
        "heterogenous graph masked autoencoders\n",
        "git hub look for it. reimplement model,\n",
        "\n",
        "1. drug traffickers is a big problem in united states and in social media\n",
        "2. dealers people who follow them, freinds are high likely to be drug traffickers\n",
        "\n",
        "2. limited dataset to train drug trafficking model. Manually labeled and annotated dataset,\n",
        "3. build model to handle inbalanced data, bc pos users are much smaller than neg users.\n",
        "\n",
        "\n",
        "RUn/gat/gin on hetergoenous graphs ie. aminer, dblp and lastfm.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
