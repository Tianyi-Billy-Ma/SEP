{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNTelIQvMg5E",
        "outputId": "ec7242b2-5d43-4c19-fa04-790382c1d014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import os\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import AMiner\n",
        "from torch_geometric.nn import MetaPath2Vec\n",
        "import torch_geometric.transforms as T\n"
      ],
      "metadata": {
        "id": "U4cBlgihNK_u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-VYdZ25DyEOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\metapath2vec\\Aminer'\n",
        "dataset = AMiner(path)\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "KqeIb2d-SYyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69905ba9-2f99-403c-db1f-95f0d70f4adf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.dropbox.com/s/1bnz8r7mofx0osf/net_aminer.zip?dl=1\n",
            "Extracting C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\metapath2vec\\Aminer/net_aminer.zip\n",
            "Downloading https://www.dropbox.com/s/nkocx16rpl4ydde/label.zip?dl=1\n",
            "Extracting C:\\Users\\16822\\Research Project SER\\SEP-NHANES\\lmolina3\\src\\utils\\metapath2vec\\Aminer/raw/label.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_edge_types = [(x[2], \"{}_{}\".format('rev', x[1]), x[0]) for x in data.edge_types]\n",
        "\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,  # fraction of data held out for validation\n",
        "    num_test=0.8, # fraction of data held out for test\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types = data.edge_types,\n",
        "    rev_edge_types= reverse_edge_types\n",
        ")\n",
        "train_data, val_data, test_data = transform(data)"
      ],
      "metadata": {
        "id": "nj4M2KoqA96v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)\n",
        "print('')\n",
        "print(f'{val_data}')\n",
        "print('')\n",
        "print(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVne0HL6BMAf",
        "outputId": "d6e662be-6917-4f47-db27-fd2e55dac3c1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={\n",
            "    edge_index=[2, 932361],\n",
            "    edge_label=[932361],\n",
            "    edge_label_index=[2, 932361],\n",
            "  },\n",
            "  (author, writes, paper)={\n",
            "    edge_index=[2, 932361],\n",
            "    edge_label=[932361],\n",
            "    edge_label_index=[2, 932361],\n",
            "  },\n",
            "  (paper, published_in, venue)={\n",
            "    edge_index=[2, 319441],\n",
            "    edge_label=[319441],\n",
            "    edge_label_index=[2, 319441],\n",
            "  },\n",
            "  (venue, publishes, paper)={\n",
            "    edge_index=[2, 319441],\n",
            "    edge_label=[319441],\n",
            "    edge_label_index=[2, 319441],\n",
            "  },\n",
            "  (author, rev_written_by, paper)={},\n",
            "  (paper, rev_writes, author)={},\n",
            "  (venue, rev_published_in, paper)={},\n",
            "  (paper, rev_publishes, venue)={}\n",
            ")\n",
            "\n",
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={\n",
            "    edge_index=[2, 932361],\n",
            "    edge_label=[932360],\n",
            "    edge_label_index=[2, 932360],\n",
            "  },\n",
            "  (author, writes, paper)={\n",
            "    edge_index=[2, 932361],\n",
            "    edge_label=[932360],\n",
            "    edge_label_index=[2, 932360],\n",
            "  },\n",
            "  (paper, published_in, venue)={\n",
            "    edge_index=[2, 319441],\n",
            "    edge_label=[319440],\n",
            "    edge_label_index=[2, 319440],\n",
            "  },\n",
            "  (venue, publishes, paper)={\n",
            "    edge_index=[2, 319441],\n",
            "    edge_label=[319440],\n",
            "    edge_label_index=[2, 319440],\n",
            "  },\n",
            "  (author, rev_written_by, paper)={},\n",
            "  (paper, rev_writes, author)={},\n",
            "  (venue, rev_published_in, paper)={},\n",
            "  (paper, rev_publishes, venue)={}\n",
            ")\n",
            "\n",
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={\n",
            "    edge_index=[2, 1864721],\n",
            "    edge_label=[7458884],\n",
            "    edge_label_index=[2, 7458884],\n",
            "  },\n",
            "  (author, writes, paper)={\n",
            "    edge_index=[2, 1864721],\n",
            "    edge_label=[7458884],\n",
            "    edge_label_index=[2, 7458884],\n",
            "  },\n",
            "  (paper, published_in, venue)={\n",
            "    edge_index=[2, 638881],\n",
            "    edge_label=[2555524],\n",
            "    edge_label_index=[2, 2555524],\n",
            "  },\n",
            "  (venue, publishes, paper)={\n",
            "    edge_index=[2, 638881],\n",
            "    edge_label=[2555524],\n",
            "    edge_label_index=[2, 2555524],\n",
            "  },\n",
            "  (author, rev_written_by, paper)={},\n",
            "  (paper, rev_writes, author)={},\n",
            "  (venue, rev_published_in, paper)={},\n",
            "  (paper, rev_publishes, venue)={}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGFFPaNz5Bjn",
        "outputId": "3a6d28c1-f87a-46bd-9f79-c48a1a36a96e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('paper',\n",
              "  'written_by',\n",
              "  'author'): tensor([[      0,       1,       2,  ..., 3194404, 3194404, 3194404],\n",
              "         [      0,       1,       2,  ...,    4393,   21681,  317436]]),\n",
              " ('author',\n",
              "  'writes',\n",
              "  'paper'): tensor([[      0,       1,       2,  ...,    4393,   21681,  317436],\n",
              "         [      0,       1,       2,  ..., 3194404, 3194404, 3194404]]),\n",
              " ('paper',\n",
              "  'published_in',\n",
              "  'venue'): tensor([[      0,       1,       2,  ..., 3194402, 3194403, 3194404],\n",
              "         [   2190,    2190,    2190,  ...,    3148,    3148,    3148]]),\n",
              " ('venue',\n",
              "  'publishes',\n",
              "  'paper'): tensor([[   2190,    2190,    2190,  ...,    3148,    3148,    3148],\n",
              "         [      0,       1,       2,  ..., 3194402, 3194403, 3194404]])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jiePHU-Q9FsK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the overall structure of the dataset\n",
        "print(\"Overall structure of the dataset:\")\n",
        "print(data)\n",
        "\n",
        "# List all node types and their features\n",
        "print(\"\\nNode types and their features:\")\n",
        "for node_type in data.node_types:\n",
        "    print(f\"Node type: {node_type}\")\n",
        "    for key, value in data[node_type].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# List all edge types and their indices\n",
        "print(\"\\nEdge types and their indices:\")\n",
        "for edge_type in data.edge_types:\n",
        "    print(f\"Edge type: {edge_type}\")\n",
        "    print(f\"  Edge index shape: {data[edge_type].edge_index.shape}\")\n",
        "\n",
        "# Example of accessing specific node features\n",
        "print(\"\\nExample of accessing specific node features:\")\n",
        "author_features = data['author']\n",
        "print(\"Author features:\", author_features)\n",
        "\n",
        "# Example of accessing specific edge indices\n",
        "print(\"\\nExample of accessing specific edge indices:\")\n",
        "author_paper_edge_index = data['author', 'writes', 'paper'].edge_index\n",
        "print(\"Author writes paper edge index:\", author_paper_edge_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scu4ZZ4MyJsD",
        "outputId": "75107708-ebfb-4b59-9722-5f74c3d9ce8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall structure of the dataset:\n",
            "HeteroData(\n",
            "  author={\n",
            "    y=[246678],\n",
            "    y_index=[246678],\n",
            "    num_nodes=1693531,\n",
            "  },\n",
            "  venue={\n",
            "    y=[134],\n",
            "    y_index=[134],\n",
            "    num_nodes=3883,\n",
            "  },\n",
            "  paper={ num_nodes=3194405 },\n",
            "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
            "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
            "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
            "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
            ")\n",
            "\n",
            "Node types and their features:\n",
            "Node type: author\n",
            "  y: tensor([0, 2, 5,  ..., 0, 1, 5])\n",
            "  y_index: tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374])\n",
            "  num_nodes: 1693531\n",
            "Node type: venue\n",
            "  y: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
            "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n",
            "  y_index: tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
            "        2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
            "        1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
            "         492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
            "         721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
            "         477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
            "        3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
            "        1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
            "        2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
            "        2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
            "        1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
            "         208,  462])\n",
            "  num_nodes: 3883\n",
            "Node type: paper\n",
            "  num_nodes: 3194405\n",
            "\n",
            "Edge types and their indices:\n",
            "Edge type: ('paper', 'written_by', 'author')\n",
            "  Edge index shape: torch.Size([2, 9323605])\n",
            "Edge type: ('author', 'writes', 'paper')\n",
            "  Edge index shape: torch.Size([2, 9323605])\n",
            "Edge type: ('paper', 'published_in', 'venue')\n",
            "  Edge index shape: torch.Size([2, 3194405])\n",
            "Edge type: ('venue', 'publishes', 'paper')\n",
            "  Edge index shape: torch.Size([2, 3194405])\n",
            "\n",
            "Example of accessing specific node features:\n",
            "Author features: {'y': tensor([0, 2, 5,  ..., 0, 1, 5]), 'y_index': tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374]), 'num_nodes': 1693531}\n",
            "\n",
            "Example of accessing specific edge indices:\n",
            "Author writes paper edge index: tensor([[      0,       1,       2,  ...,    4393,   21681,  317436],\n",
            "        [      0,       1,       2,  ..., 3194404, 3194404, 3194404]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metapath = [\n",
        "    ('author', 'writes', 'paper'),\n",
        "    ('paper', 'published_in', 'venue'),\n",
        "    ('venue', 'publishes', 'paper'),\n",
        "    ('paper', 'written_by', 'author'),\n",
        "]\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('Cuda')\n",
        "    device = torch.device('cuda')\n",
        "elif torch_geometric.is_xpu_available():\n",
        "    print('xpu')\n",
        "    device = torch.device('xpu')\n",
        "else:\n",
        "    print('cpu')\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = MetaPath2Vec(data.edge_index_dict, embedding_dim=128,\n",
        "                     metapath=metapath, walk_length=50, context_size=7,\n",
        "                     walks_per_node=5, num_negative_samples=5,\n",
        "                     sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=6)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v375kdoANapS",
        "outputId": "344cfa77-374e-421b-85a4-2476e3a836b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch, log_steps=1000, eval_steps=2000):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % log_steps == 0:\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
        "            total_loss = 0\n",
        "\n",
        "        if (i + 1) % eval_steps == 0:\n",
        "            author_acc, venue_acc= test()\n",
        "            print('')\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Author Acc: {author_acc:.4f}'\n",
        "                   f'Venue Acc: {venue_acc:.4f}'))\n",
        "\n",
        "def node_test(node_class, train_ratio=0.1):\n",
        "    z = model(node_class, batch=data[node_class].y_index.to(device))\n",
        "    y = data[node_class].y\n",
        "\n",
        "    perm = torch.randperm(z.size(0))\n",
        "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
        "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
        "\n",
        "    return model.test(z[train_perm], y[train_perm], z[test_perm], y[test_perm],\n",
        "                      max_iter=150)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(train_ratio=0.1):\n",
        "    model.eval()\n",
        "\n",
        "    author_acc = node_test('author')\n",
        "    venue_acc = node_test('venue')\n",
        "\n",
        "    return author_acc, venue_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "Dk1NEmrzNR-0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1, 6):\n",
        "    train(epoch)\n",
        "    # acc = test()\n",
        "    # print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')\n"
      ],
      "metadata": {
        "id": "PTxcOai_NqjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de168a0b-ddf7-40e4-c593-d4d470d74838"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Step: 01000/13231, Loss: 2.3792\n",
            "Epoch: 1, Step: 02000/13231, Loss: 2.0392\n",
            "\n",
            "Epoch: 1, Step: 02000/13231, Author Acc: 0.6363Venue Acc: 0.4793\n",
            "Epoch: 1, Step: 03000/13231, Loss: 1.7971\n",
            "Epoch: 1, Step: 04000/13231, Loss: 1.6216\n",
            "\n",
            "Epoch: 1, Step: 04000/13231, Author Acc: 0.7387Venue Acc: 0.5289\n",
            "Epoch: 1, Step: 05000/13231, Loss: 1.4902\n",
            "Epoch: 1, Step: 06000/13231, Loss: 1.3879\n",
            "\n",
            "Epoch: 1, Step: 06000/13231, Author Acc: 0.7920Venue Acc: 0.6942\n",
            "Epoch: 1, Step: 07000/13231, Loss: 1.3067\n",
            "Epoch: 1, Step: 08000/13231, Loss: 1.2403\n",
            "\n",
            "Epoch: 1, Step: 08000/13231, Author Acc: 0.8246Venue Acc: 0.6198\n",
            "Epoch: 1, Step: 09000/13231, Loss: 1.1855\n",
            "Epoch: 1, Step: 10000/13231, Loss: 1.1401\n",
            "\n",
            "Epoch: 1, Step: 10000/13231, Author Acc: 0.8446Venue Acc: 0.8182\n",
            "Epoch: 1, Step: 11000/13231, Loss: 1.1019\n",
            "Epoch: 1, Step: 12000/13231, Loss: 1.0695\n",
            "\n",
            "Epoch: 1, Step: 12000/13231, Author Acc: 0.8591Venue Acc: 0.4959\n",
            "Epoch: 1, Step: 13000/13231, Loss: 1.0417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Step: 01000/13231, Loss: 1.0126\n",
            "Epoch: 2, Step: 02000/13231, Loss: 0.9930\n",
            "\n",
            "Epoch: 2, Step: 02000/13231, Author Acc: 0.8739Venue Acc: 0.8678\n",
            "Epoch: 2, Step: 03000/13231, Loss: 0.9761\n",
            "Epoch: 2, Step: 04000/13231, Loss: 0.9614\n",
            "\n",
            "Epoch: 2, Step: 04000/13231, Author Acc: 0.8802Venue Acc: 0.7190\n",
            "Epoch: 2, Step: 05000/13231, Loss: 0.9485\n",
            "Epoch: 2, Step: 06000/13231, Loss: 0.9373\n",
            "\n",
            "Epoch: 2, Step: 06000/13231, Author Acc: 0.8850Venue Acc: 0.6612\n",
            "Epoch: 2, Step: 07000/13231, Loss: 0.9276\n",
            "Epoch: 2, Step: 08000/13231, Loss: 0.9189\n",
            "\n",
            "Epoch: 2, Step: 08000/13231, Author Acc: 0.8895Venue Acc: 0.8099\n",
            "Epoch: 2, Step: 09000/13231, Loss: 0.9110\n",
            "Epoch: 2, Step: 10000/13231, Loss: 0.9041\n",
            "\n",
            "Epoch: 2, Step: 10000/13231, Author Acc: 0.8919Venue Acc: 0.7438\n",
            "Epoch: 2, Step: 11000/13231, Loss: 0.8982\n",
            "Epoch: 2, Step: 12000/13231, Loss: 0.8926\n",
            "\n",
            "Epoch: 2, Step: 12000/13231, Author Acc: 0.8958Venue Acc: 0.5372\n",
            "Epoch: 2, Step: 13000/13231, Loss: 0.8878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Step: 01000/13231, Loss: 0.8822\n",
            "Epoch: 3, Step: 02000/13231, Loss: 0.8783\n",
            "\n",
            "Epoch: 3, Step: 02000/13231, Author Acc: 0.8994Venue Acc: 0.5785\n",
            "Epoch: 3, Step: 03000/13231, Loss: 0.8748\n",
            "Epoch: 3, Step: 04000/13231, Loss: 0.8716\n",
            "\n",
            "Epoch: 3, Step: 04000/13231, Author Acc: 0.9007Venue Acc: 0.6942\n",
            "Epoch: 3, Step: 05000/13231, Loss: 0.8688\n",
            "Epoch: 3, Step: 06000/13231, Loss: 0.8660\n",
            "\n",
            "Epoch: 3, Step: 06000/13231, Author Acc: 0.9019Venue Acc: 0.5207\n",
            "Epoch: 3, Step: 07000/13231, Loss: 0.8636\n",
            "Epoch: 3, Step: 08000/13231, Loss: 0.8614\n",
            "\n",
            "Epoch: 3, Step: 08000/13231, Author Acc: 0.9045Venue Acc: 0.6942\n",
            "Epoch: 3, Step: 09000/13231, Loss: 0.8593\n",
            "Epoch: 3, Step: 10000/13231, Loss: 0.8574\n",
            "\n",
            "Epoch: 3, Step: 10000/13231, Author Acc: 0.9056Venue Acc: 0.6198\n",
            "Epoch: 3, Step: 11000/13231, Loss: 0.8556\n",
            "Epoch: 3, Step: 12000/13231, Loss: 0.8538\n",
            "\n",
            "Epoch: 3, Step: 12000/13231, Author Acc: 0.9078Venue Acc: 0.4793\n",
            "Epoch: 3, Step: 13000/13231, Loss: 0.8525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Step: 01000/13231, Loss: 0.8504\n",
            "Epoch: 4, Step: 02000/13231, Loss: 0.8492\n",
            "\n",
            "Epoch: 4, Step: 02000/13231, Author Acc: 0.9097Venue Acc: 0.7025\n",
            "Epoch: 4, Step: 03000/13231, Loss: 0.8480\n",
            "Epoch: 4, Step: 04000/13231, Loss: 0.8468\n",
            "\n",
            "Epoch: 4, Step: 04000/13231, Author Acc: 0.9109Venue Acc: 0.7521\n",
            "Epoch: 4, Step: 05000/13231, Loss: 0.8458\n",
            "Epoch: 4, Step: 06000/13231, Loss: 0.8448\n",
            "\n",
            "Epoch: 4, Step: 06000/13231, Author Acc: 0.9109Venue Acc: 0.7603\n",
            "Epoch: 4, Step: 07000/13231, Loss: 0.8440\n",
            "Epoch: 4, Step: 08000/13231, Loss: 0.8431\n",
            "\n",
            "Epoch: 4, Step: 08000/13231, Author Acc: 0.9122Venue Acc: 0.5207\n",
            "Epoch: 4, Step: 09000/13231, Loss: 0.8423\n",
            "Epoch: 4, Step: 10000/13231, Loss: 0.8415\n",
            "\n",
            "Epoch: 4, Step: 10000/13231, Author Acc: 0.9142Venue Acc: 0.8264\n",
            "Epoch: 4, Step: 11000/13231, Loss: 0.8408\n",
            "Epoch: 4, Step: 12000/13231, Loss: 0.8400\n",
            "\n",
            "Epoch: 4, Step: 12000/13231, Author Acc: 0.9150Venue Acc: 0.5785\n",
            "Epoch: 4, Step: 13000/13231, Loss: 0.8394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Step: 01000/13231, Loss: 0.8384\n",
            "Epoch: 5, Step: 02000/13231, Loss: 0.8380\n",
            "\n",
            "Epoch: 5, Step: 02000/13231, Author Acc: 0.9156Venue Acc: 0.6529\n",
            "Epoch: 5, Step: 03000/13231, Loss: 0.8376\n",
            "Epoch: 5, Step: 04000/13231, Loss: 0.8371\n",
            "\n",
            "Epoch: 5, Step: 04000/13231, Author Acc: 0.9167Venue Acc: 0.8678\n",
            "Epoch: 5, Step: 05000/13231, Loss: 0.8366\n",
            "Epoch: 5, Step: 06000/13231, Loss: 0.8361\n",
            "\n",
            "Epoch: 5, Step: 06000/13231, Author Acc: 0.9166Venue Acc: 0.7438\n",
            "Epoch: 5, Step: 07000/13231, Loss: 0.8357\n",
            "Epoch: 5, Step: 08000/13231, Loss: 0.8354\n",
            "\n",
            "Epoch: 5, Step: 08000/13231, Author Acc: 0.9169Venue Acc: 0.6529\n",
            "Epoch: 5, Step: 09000/13231, Loss: 0.8351\n",
            "Epoch: 5, Step: 10000/13231, Loss: 0.8346\n",
            "\n",
            "Epoch: 5, Step: 10000/13231, Author Acc: 0.9179Venue Acc: 0.5041\n",
            "Epoch: 5, Step: 11000/13231, Loss: 0.8344\n",
            "Epoch: 5, Step: 12000/13231, Loss: 0.8341\n",
            "\n",
            "Epoch: 5, Step: 12000/13231, Author Acc: 0.9186Venue Acc: 0.4628\n",
            "Epoch: 5, Step: 13000/13231, Loss: 0.8339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['author']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13ApWs992MtD",
        "outputId": "fd4551e9-0030-4434-b5a3-fa953408a297"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 168866, 1327323,     870,  ...,  168759,  254769,  264374])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['venue']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLh9MUid2QSD",
        "outputId": "8dbbec21-c756-4c03-8202-d26cbe66d0fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'y': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
              "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]), 'y_index': tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
              "        2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
              "        1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
              "         492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
              "         721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
              "         477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
              "        3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
              "        1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
              "        2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
              "        2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
              "        1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
              "         208,  462]), 'num_nodes': 3883}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['paper']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2KsrHFt2TUq",
        "outputId": "039f79f0-2ea7-46bb-8513-8566484acf54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_nodes': 3194405}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "10% training,10%validation, 80% test, splitting the training mask and split evenly by the label\n",
        "DBLP hetero\n",
        "LastFM\n",
        "author node; venue nodes; paper nodes\n",
        "\n",
        "run DBLP and LastFM the same splits\n",
        "\n",
        "heterogenous graph masked autoencoders\n",
        "git hub look for it. reimplement model,\n",
        "\n",
        "1. drug traffickers is a big problem in united states and in social media\n",
        "2. dealers people who follow them, freinds are high likely to be drug traffickers\n",
        "\n",
        "2. limited dataset to train drug trafficking model. Manually labeled and annotated dataset,\n",
        "3. build model to handle inbalanced data, bc pos users are much smaller than neg users.\n",
        "\n",
        "\n",
        "RUn/gat/gin on hetergoenous graphs ie. aminer, dblp and lastfm.\n",
        "\n"
      ],
      "metadata": {
        "id": "p2QH9HDnXFcb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}