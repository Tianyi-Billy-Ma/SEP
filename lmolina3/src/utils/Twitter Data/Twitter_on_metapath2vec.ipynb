{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "936W5D7n3ifL",
        "outputId": "b14aa8f4-7f11-4e4b-bce9-974ae8e962a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pickle\n",
        "import json\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import MetaPath2Vec\n",
        "import sklearn.metrics\n",
        "import sklearn\n",
        "import os\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "96rQmKQo3pqa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Uj82xt35GS",
        "outputId": "5a15738c-74f8-4d10-bd76-572e792579bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.load(os.path.join(os.getcwd(), 'drive','MyDrive','Summer Enrichment program ', 'updated_twitter_hetero_data.pt'))"
      ],
      "metadata": {
        "id": "s7WiF34s4CW_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFUB2GTZ36Ea",
        "outputId": "f18e629c-2fee-4536-bbec-dc931b646634"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  user={\n",
              "    x=[28839, 768],\n",
              "    y=[28839],\n",
              "  },\n",
              "  tweet={ x=[118697, 768] },\n",
              "  keyword={ x=[288, 768] },\n",
              "  (user, to -->, user)={ edge_index=[2, 201142] },\n",
              "  (user, to -->, keyword)={ edge_index=[2, 64997] },\n",
              "  (keyword, <-- to, user)={ edge_index=[2, 64997] },\n",
              "  (user, to -->, tweet)={ edge_index=[2, 162894] },\n",
              "  (tweet, <-- to, user)={ edge_index=[2, 162894] },\n",
              "  (tweet, to -->, keyword)={ edge_index=[2, 299997] },\n",
              "  (keyword, <-- to, tweet)={ edge_index=[2, 299997] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metapath = [\n",
        "    ('user', 'to -->', 'user'),\n",
        "        ('user', 'to -->', 'keyword'),\n",
        "        ('keyword', '<-- to', 'user'),\n",
        "        ('user', 'to -->', 'tweet'),\n",
        "        ('tweet', '<-- to', 'user'),\n",
        "        ('user', 'to -->', 'tweet'),\n",
        "        ('tweet', 'to -->', 'keyword'),\n",
        "        ('keyword', '<-- to', 'tweet'),\n",
        "        ('tweet', '<-- to', 'user'),\n",
        "]\n"
      ],
      "metadata": {
        "id": "U2F3Hy7o4H2t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print('runing on gpu')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "i98cDbHK4RKR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = MetaPath2Vec(data.edge_index_dict, embedding_dim=256,\n",
        "                     metapath=metapath, walk_length=10, context_size=4,\n",
        "                     walks_per_node=10, num_negative_samples=5,\n",
        "                     sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=64, shuffle=True, num_workers=2)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.0005) # lr was 0.001, 0.0001\n",
        "\n",
        "classifier = torch.nn.Sequential(\n",
        "    torch.nn.Linear(256, 128),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(128, 64),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(64, 4)\n",
        ").to(device)\n",
        "\n",
        "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.0005, weight_decay=1e-5) # lr 0.001"
      ],
      "metadata": {
        "id": "_hEFMoYq4Up7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch, train_perm, valid_perm, test_perm, log_steps=200, eval_steps=1000):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % log_steps == 0:\n",
        "            print(f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, Loss: {total_loss / log_steps:.4f}')\n",
        "            total_loss = 0\n",
        "        if (i + 1) % eval_steps == 0:\n",
        "            acc, f1_score = test(test_perm)\n",
        "            print(f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, Acc: {acc:.4f}, f1 score: {f1_score:.4f}')\n",
        "\n",
        "    y = data['user'].y\n",
        "    classifier_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    # forward prog and get outputs + accuracy on train mask\n",
        "    user_embs = model('user')\n",
        "    output = classifier(user_embs)\n",
        "\n",
        "    _, predicted = torch.max(output[train_perm], dim=1)\n",
        "    acc_train = sklearn.metrics.accuracy_score(y[train_perm].cpu().numpy(), predicted.cpu().detach().numpy())\n",
        "\n",
        "    # loss and backprog and updated weight\n",
        "    pred_loss = F.cross_entropy(output[train_perm], y[train_perm])\n",
        "    pred_loss.backward()\n",
        "    classifier_optimizer.step()\n",
        "\n",
        "    # gain accuracy on val mask\n",
        "    loss_val = F.cross_entropy(output[valid_perm], y[valid_perm])\n",
        "    acc_val = sklearn.metrics.accuracy_score(y[valid_perm].cpu().numpy(), torch.max(output[valid_perm], dim=1)[1].cpu().detach().numpy())\n",
        "    print('Train loss {:.4f}, Train Accuracy: {:.4f}'.format(pred_loss.item(), acc_train),\n",
        "          'Val loss: {:.4f}, Val Accuracy: {:.4f}'.format(loss_val.item(), acc_val))\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(test_perm):\n",
        "    model.eval()\n",
        "    # get embeddings and labels\n",
        "    z = model(\"user\")\n",
        "    y = data['user'].y\n",
        "\n",
        "    # get accuracy and f1_score on test perm\n",
        "    _, predicted = torch.max(z[test_perm], dim=1)\n",
        "    accuracy = sklearn.metrics.accuracy_score(y[test_perm].cpu().numpy(), predicted.cpu().detach().numpy())\n",
        "    f1_score = sklearn.metrics.f1_score(y[test_perm].cpu().numpy(), predicted.cpu().detach().numpy(), average=\"weighted\")\n",
        "    return accuracy, f1_score\n",
        "\n",
        "for i in range(5):\n",
        "    accuracy = []\n",
        "    f1_scores = []\n",
        "    perm = torch.randperm(28839)\n",
        "    # create trian, val, and test mask\n",
        "    train_perm, valid_perm, test_perm = perm[:int(28839 * 0.1)], perm[int(28839 * 0.1):int(28839 * 0.2)], perm[int(28839 *0.2):]\n",
        "    print('Run: {}'.format(i + 1))\n",
        "    for epoch in range(1, 10):\n",
        "        train(epoch, train_perm, valid_perm, test_perm)\n",
        "        acc, f1_score = test(test_perm)\n",
        "        print(f'Epoch: {epoch}, Accuracy: {acc:.4f}, F1 score {f1_score:.4f}')\n",
        "        accuracy.append(acc)\n",
        "        f1_scores.append(f1_score)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3-rZBat4b1-",
        "outputId": "895150fa-9fc5-4ed8-ad32-a07e839d4d0e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run: 1\n",
            "Epoch: 1, Step: 00200/451, Loss: 13.4677\n",
            "Epoch: 1, Step: 00400/451, Loss: 12.9269\n",
            "Train loss 1.4170, Train Accuracy: 0.1637 Val loss: 1.4193, Val Accuracy: 0.1671\n",
            "Epoch: 1, Accuracy: 0.0046, F1 score 0.0090\n",
            "Epoch: 2, Step: 00200/451, Loss: 12.2983\n",
            "Epoch: 2, Step: 00400/451, Loss: 11.9040\n",
            "Train loss 1.3870, Train Accuracy: 0.2400 Val loss: 1.3873, Val Accuracy: 0.2490\n",
            "Epoch: 2, Accuracy: 0.0046, F1 score 0.0090\n",
            "Epoch: 3, Step: 00200/451, Loss: 11.4221\n",
            "Epoch: 3, Step: 00400/451, Loss: 11.0994\n",
            "Train loss 1.3583, Train Accuracy: 0.3541 Val loss: 1.3595, Val Accuracy: 0.3433\n",
            "Epoch: 3, Accuracy: 0.0045, F1 score 0.0088\n",
            "Epoch: 4, Step: 00200/451, Loss: 10.7118\n",
            "Epoch: 4, Step: 00400/451, Loss: 10.4303\n",
            "Train loss 1.3271, Train Accuracy: 0.4929 Val loss: 1.3287, Val Accuracy: 0.4743\n",
            "Epoch: 4, Accuracy: 0.0045, F1 score 0.0088\n",
            "Epoch: 5, Step: 00200/451, Loss: 10.0916\n",
            "Epoch: 5, Step: 00400/451, Loss: 9.8572\n",
            "Train loss 1.3003, Train Accuracy: 0.5994 Val loss: 1.3015, Val Accuracy: 0.5846\n",
            "Epoch: 5, Accuracy: 0.0044, F1 score 0.0086\n",
            "Epoch: 6, Step: 00200/451, Loss: 9.5412\n",
            "Epoch: 6, Step: 00400/451, Loss: 9.3182\n",
            "Train loss 1.2729, Train Accuracy: 0.6916 Val loss: 1.2763, Val Accuracy: 0.6789\n",
            "Epoch: 6, Accuracy: 0.0044, F1 score 0.0086\n",
            "Epoch: 7, Step: 00200/451, Loss: 9.0353\n",
            "Epoch: 7, Step: 00400/451, Loss: 8.8281\n",
            "Train loss 1.2461, Train Accuracy: 0.7752 Val loss: 1.2452, Val Accuracy: 0.7764\n",
            "Epoch: 7, Accuracy: 0.0045, F1 score 0.0089\n",
            "Epoch: 8, Step: 00200/451, Loss: 8.5522\n",
            "Epoch: 8, Step: 00400/451, Loss: 8.3602\n",
            "Train loss 1.2188, Train Accuracy: 0.8189 Val loss: 1.2192, Val Accuracy: 0.8162\n",
            "Epoch: 8, Accuracy: 0.0047, F1 score 0.0092\n",
            "Epoch: 9, Step: 00200/451, Loss: 8.0961\n",
            "Epoch: 9, Step: 00400/451, Loss: 7.9156\n",
            "Train loss 1.1900, Train Accuracy: 0.8460 Val loss: 1.1912, Val Accuracy: 0.8519\n",
            "Epoch: 9, Accuracy: 0.0049, F1 score 0.0096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc, f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SQmSGNY8Pev",
        "outputId": "25b9dc1f-87ce-49d1-81e0-bffa7ce90e12"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.007541608876560333 0.01470250676699084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xkGSGqpT5zUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}