{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx9lc1L1BUrH",
        "outputId": "4960ba6b-5e45-496b-e36d-d85133067726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv, GATConv, GINConv, MLP\n",
        "import sklearn.metrics as metrics"
      ],
      "metadata": {
        "id": "e18PzEwkBmK0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def json_open(file_path):\n",
        "  with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "  return data\n",
        "\n",
        "\n",
        "def pickle_open(file_path):\n",
        "  with open(file_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "  return data"
      ],
      "metadata": {
        "id": "BXmFyWCOBb4N"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.path.exists('/content/drive/Shareddrives/SEP/Data/edges.json')\n",
        "path = '/content/drive/Shareddrives/SEP/Data'\n",
        "edges = json_open(os.path.join(path,'edges.json'))\n",
        "labels = json_open(os.path.join(path,'labels.json'))\n",
        "keyword_embeddings = pickle_open(os.path.join(path,'keyword_embeddings.pkl'))\n",
        "tweet_embeddings = pickle_open(os.path.join(path,'tweet_embeddings.pkl'))\n",
        "user_embeddings = pickle_open(os.path.join(path,'user_embeddings.pkl'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igGv8Z03Bfr6",
        "outputId": "6dde2ca4-5632-43bd-b49e-bddc9bc73435"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all ids and add them to a dictionary with correspoding index\n",
        "all_ids = list(list(user_embeddings['ids']) + list(tweet_embeddings['ids']) + list(keyword_embeddings['ids']))\n",
        "ids_to_index = {ids: i for i, ids in enumerate(all_ids)}\n",
        "\n",
        "# concatenate all embeddings and add convert to tensor\n",
        "all_embeddings = np.concatenate([user_embeddings['embeddings'], tweet_embeddings['embeddings'], keyword_embeddings['embeddings']], axis=0)\n",
        "x = torch.tensor(all_embeddings, dtype=torch.float)\n",
        "\n",
        "# make edge index correspoding to source_id to target_id\n",
        "edge_index = [[], []]\n",
        "for edge in edges:\n",
        "  source_id = edge['source_id']\n",
        "  target_id = edge['target_id']\n",
        "  edge_index[0].append(ids_to_index[source_id])\n",
        "  edge_index[1].append(ids_to_index[target_id])\n",
        "\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "\n",
        "# get all the lables in labels\n",
        "labels_val = set()\n",
        "for value in labels.values():\n",
        "  if value not in labels_val:\n",
        "    labels_val.add(value)\n",
        "\n",
        "# from the ids list get the label corresponding to ids, if no id is found it is negative (keyword_ids are not in labels)\n",
        "labels_list = [labels.get(ids, 'Negative') for ids in all_ids]\n",
        "\n",
        "# make label values to numeric\n",
        "labels_dict = { label: i for i, label in enumerate(labels_val)}\n",
        "labels_list = [labels_dict[label] for label in labels_list]\n",
        "\n",
        "y = torch.tensor(labels_list, dtype=torch.long)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xkzcI9nkBv6d"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xER1HosAshsH"
      },
      "outputs": [],
      "source": [
        "# create mask\n",
        "num_nodes = x.size(0)\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "num_train = int(0.1 * num_nodes)\n",
        "num_val = int(0.1 * num_nodes)\n",
        "train_mask[:num_train] = True\n",
        "val_mask[num_train:num_train + num_val] = True\n",
        "test_mask[num_train + num_val:] = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKFQpr3EC0GK",
        "outputId": "8c4d6746-18f8-48fa-dbae-7b5f357b7f3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[147824, 768], edge_index=[2, 729030], y=[147824], train_mask=[147824], val_mask=[147824], test_mask=[147824])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(data, os.path.join(os.getcwd(), 'drive', 'MyDrive','Summer Enrichment program ','twitter_data_homogeneous' ))\n"
      ],
      "metadata": {
        "id": "zDtwjOChKZD9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.load(os.path.join(os.getcwd(), 'drive', 'MyDrive','Summer Enrichment program ','twitter_data_homogeneous' ))"
      ],
      "metadata": {
        "id": "8T0CAftYKweQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, input_feats, num_hidden, num_classes, dropout = 0.5):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.gc1 = GCNConv(input_feats, num_hidden)\n",
        "        self.gc2 = GCNConv(num_hidden, num_classes)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.gc1(x, edge_index))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, features, hidden, classes, heads=4, dropout=0.5):\n",
        "        super(GAT, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.gat1 = GATConv(features, hidden, heads=heads, dropout=dropout)\n",
        "        self.gat2 = GATConv(hidden * heads, classes, heads=1, concat=True, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gat2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "61izUTKrE-tS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "3y0GU_mAIt2K"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(input_feats=data.x.size(1), num_hidden=16, num_classes=data.y.max().item() + 1  ).to(device)\n",
        "model_gat = GAT(features=data.x.size(1), hidden=16, classes=data.y.max().item() + 1).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "data.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ENYlMJSGI3e",
        "outputId": "2e4d063a-1837-4159-91c6-cfe7d7053ad9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[147824, 768], edge_index=[2, 729030], y=[147824], train_mask=[147824], val_mask=[147824], test_mask=[147824])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epoch, features, edge_index, labels, train_mask, val_mask):\n",
        "    model.train()\n",
        "\n",
        "    # training\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features, edge_index)\n",
        "    loss_train = F.nll_loss(output[train_mask], labels[train_mask])\n",
        "\n",
        "    # accuarcy\n",
        "    preds = output[train_mask].max(1)[1].type_as(labels[train_mask])\n",
        "    correct = preds.eq(labels[train_mask]).double()\n",
        "    correct = correct.sum()\n",
        "    acc_train = correct / len(labels[train_mask])\n",
        "\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validation\n",
        "    loss_val = F.nll_loss(output[val_mask], labels[val_mask])\n",
        "    preds = output[val_mask].max(1)[1].type_as(labels[val_mask])\n",
        "    correct = preds.eq(labels[val_mask]).double()\n",
        "    correct = correct.sum()\n",
        "    acc_val = correct / len(labels[val_mask])\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      print('Epoch: {:04d}'.format(epoch+1),\n",
        "            'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "            'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "            'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "            'acc_val: {:.4f}'.format(acc_val.item()))\n",
        "\n",
        "\n",
        "def test(model, features, edge_index, labels, test_mask):\n",
        "    model.eval()\n",
        "    output = model(features, edge_index)\n",
        "    loss_test = F.nll_loss(output[test_mask], labels[test_mask])\n",
        "\n",
        "    preds = output[test_mask].max(1)[1].type_as(labels[test_mask])\n",
        "    correct = preds.eq(labels[test_mask]).double()\n",
        "    correct = correct.sum()\n",
        "    acc_test = correct / len(labels[test_mask])\n",
        "\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test.item()),\n",
        "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
        "    return acc_test.item()"
      ],
      "metadata": {
        "id": "bbwXntwQFgK2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gcn\n",
        "test_acc_list = []\n",
        "for i in range(5):\n",
        "  for epoch in range(200):\n",
        "      train(model, epoch, data.x, data.edge_index, data.y, data.train_mask, data.val_mask)\n",
        "  acc_test = test(model, data.x, data.edge_index, data.y, data.test_mask)\n",
        "  test_acc_list.append(acc_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fLOEUKrIa-p",
        "outputId": "fa23f915-8e8d-4a57-8e6d-837d01f5c8b8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0100 loss_train: 0.5271 acc_train: 0.8361 loss_val: 0.3187 acc_val: 0.9576\n",
            "Epoch: 0200 loss_train: 0.5083 acc_train: 0.8351 loss_val: 0.3012 acc_val: 0.9570\n",
            "Test set results: loss= 0.2793 accuracy= 0.9976\n",
            "Epoch: 0100 loss_train: 0.4976 acc_train: 0.8349 loss_val: 0.3005 acc_val: 0.9526\n",
            "Epoch: 0200 loss_train: 0.4931 acc_train: 0.8376 loss_val: 0.2891 acc_val: 0.9527\n",
            "Test set results: loss= 0.2417 accuracy= 0.9976\n",
            "Epoch: 0100 loss_train: 0.4852 acc_train: 0.8399 loss_val: 0.2992 acc_val: 0.9508\n",
            "Epoch: 0200 loss_train: 0.4836 acc_train: 0.8395 loss_val: 0.2820 acc_val: 0.9499\n",
            "Test set results: loss= 0.2319 accuracy= 0.9976\n",
            "Epoch: 0100 loss_train: 0.4829 acc_train: 0.8402 loss_val: 0.2776 acc_val: 0.9502\n",
            "Epoch: 0200 loss_train: 0.4791 acc_train: 0.8431 loss_val: 0.2774 acc_val: 0.9472\n",
            "Test set results: loss= 0.2225 accuracy= 0.9976\n",
            "Epoch: 0100 loss_train: 0.4819 acc_train: 0.8410 loss_val: 0.2695 acc_val: 0.9474\n",
            "Epoch: 0200 loss_train: 0.4782 acc_train: 0.8422 loss_val: 0.2997 acc_val: 0.9462\n",
            "Test set results: loss= 0.2211 accuracy= 0.9976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy: {:.3f} +/- {:.3f}'.format(np.mean(test_acc_list), np.std(test_acc_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C5lljrEK31P",
        "outputId": "099f044f-8884-4da1-d11f-798dc38d66e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.998 +/- 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GAT\n",
        "test_acc_gat_list = []\n",
        "for i in range(5):\n",
        "  for epoch in range(200):\n",
        "      train(model_gat, epoch, data.x, data.edge_index, data.y, data.train_mask, data.val_mask)\n",
        "  test_acc_gat = test(model_gat, data.x, data.edge_index, data.y, data.test_mask)\n",
        "  test_acc_gat_list.append(test_acc_gat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRgL71gkaLNA",
        "outputId": "8a15cecc-b0b1-433d-c7f5-ce8300558565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0100 loss_train: 1.3839 acc_train: 0.2496 loss_val: 1.3857 acc_val: 0.2389\n",
            "Epoch: 0200 loss_train: 1.3841 acc_train: 0.2479 loss_val: 1.3852 acc_val: 0.2347\n",
            "Test set results: loss= 1.3823 accuracy= 0.2076\n",
            "Epoch: 0100 loss_train: 1.3878 acc_train: 0.2330 loss_val: 1.3885 acc_val: 0.2220\n",
            "Epoch: 0200 loss_train: 1.3826 acc_train: 0.2527 loss_val: 1.3831 acc_val: 0.2436\n",
            "Test set results: loss= 1.3823 accuracy= 0.2076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5qUiQHdEkQh9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}